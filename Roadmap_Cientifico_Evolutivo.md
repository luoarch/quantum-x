# Roadmap Cient√≠fico Evolutivo IA-Enhanced
## Sistema de An√°lise de Spillovers Econ√¥micos Brasil-Mundo com Intelig√™ncia Artificial

**Vers√£o:** 3.0  
**Data:** 26 de Setembro de 2025  
**Autor:** Sistema de An√°lise Econ√¥mica  
**Status:** Aprovado pelo Orientador - Revis√£o IA-Enhanced  

---

## Vis√£o Geral da Abordagem IA-Enhanced

Este roadmap implementa uma estrat√©gia **evolutiva e cientificamente rigorosa** para desenvolvimento de um sistema de an√°lise de spillovers econ√¥micos **potencializado por Intelig√™ncia Artificial**. Cada fase combina econometria tradicional com t√©cnicas modernas de ML, garantindo valida√ß√£o cient√≠fica robusta e performance superior.

### **Revolu√ß√£o IA no Projeto:**

1. **Modelagem de Rela√ß√µes N√£o-Lineares**: Neural Networks capturam spillovers que se comportam diferentemente durante crises vs. per√≠odos normais
2. **Graph Neural Networks**: Modelam spillovers indiretos (EUA ‚Üí UE ‚Üí Brasil) atrav√©s de redes de pa√≠ses
3. **Ensemble Methods**: Combinam m√∫ltiplos modelos com pesos baseados em performance out-of-sample
4. **Feature Engineering Automatizado**: AutoML descobre features preditivas automaticamente
5. **Regime Detection via Clustering**: Unsupervised Learning para detectar regimes automaticamente

### Princ√≠pios Fundamentais

1. **Replicabilidade Primeiro**: Sempre replicar papers existentes antes de inovar
2. **Valida√ß√£o Out-of-Sample Obrigat√≥ria**: Nunca reportar apenas in-sample fit
3. **Testes de Robustez M√∫ltiplos**: Pelo menos 3 especifica√ß√µes diferentes por fase
4. **Progress√£o Baseada em Evid√™ncia**: S√≥ avan√ßar se a fase anterior for cientificamente v√°lida
5. **M√©tricas de Sucesso Cient√≠ficas**: Crit√©rios objetivos e mensur√°veis

---

## Protocolo Anti-Vi√©s e Anti-Alucina√ß√£o

### **Princ√≠pios Fundamentais de Valida√ß√£o Cient√≠fica IA**

#### **1. Bias-Variance Tradeoff Cient√≠fico**
- **Problema**: Modelos complexos (IA) t√™m baixo vi√©s mas alta vari√¢ncia, modelos simples (VAR) t√™m alto vi√©s mas baixa vari√¢ncia
- **Solu√ß√£o**: Ensemble balanceado com pesos baseados em performance out-of-sample

#### **2. Valida√ß√£o Cruzada Temporal Rigorosa**
- **Problema**: Valida√ß√£o cruzada aleat√≥ria causa data leakage em dados temporais
- **Solu√ß√£o**: Time Series Cross-Validation espec√≠fico para spillover analysis

#### **3. Robustez a Outliers e Quebras Estruturais**
- **Problema**: Modelos IA s√£o sens√≠veis a outliers e mudan√ßas estruturais
- **Solu√ß√£o**: M√©todos robustos e detec√ß√£o de outliers estrutural

#### **4. Controle de Escopo e Incerteza**
- **Problema**: Modelos IA podem "alucinar" em regimes desconhecidos
- **Solu√ß√£o**: Quantifica√ß√£o de incerteza e detec√ß√£o de out-of-scope

#### **5. Ground Truth Anchoring**
- **Problema**: Predi√ß√µes podem ser economicamente implaus√≠veis
- **Solu√ß√£o**: Verifica√ß√µes de sanidade econ√¥mica e ancoragem em fatos conhecidos

---

## Fase 1: Funda√ß√£o Emp√≠rica IA-Enhanced (6-9 meses)
### MVP Cient√≠fico: VAR + Neural Enhancement Brasil-EUA

#### Objetivo Limitado
Quantificar spillovers de choques monet√°rios dos EUA para o Brasil usando **VAR + Neural Networks** para capturar n√£o-linearidades.

#### Metodologia IA-Enhanced
- **Modelo Base**: VAR(p) bivariado (Taxa Fed + Selic)
- **Enhancement IA**: MLPRegressor para capturar n√£o-linearidades nos res√≠duos
- **Dados**: S√©ries mensais, 2000-2025 (300 observa√ß√µes)
- **Valida√ß√£o**: Out-of-sample de 24 meses, comparar com VAR puro e random walk
- **Target Performance**: Superar VAR tradicional em 15%+ RMSE

#### Implementa√ß√£o IA-Enhanced com Protocolo Anti-Vi√©s

```python
# Fase 1: VAR + Neural Enhancement com Valida√ß√£o Cient√≠fica Rigorosa
from statsmodels.tsa.vector_ar.var_model import VAR
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from statsmodels.robust import robust_linear_model
from sklearn.model_selection import TimeSeriesSplit
import numpy as np

# 1. Time Series Cross-Validation Espec√≠fico
def time_series_cv_spillover(data, n_splits=5, test_size=12):
    """
    Valida√ß√£o cruzada espec√≠fica para spillover analysis
    Evita data leakage temporal
    """
    for i in range(n_splits):
        train_end = len(data) - (n_splits-i) * test_size
        test_start = train_end
        test_end = train_end + test_size
        
        train_data = data[:train_end]
        test_data = data[test_start:test_end]
        
        yield train_data, test_data

# 2. Detec√ß√£o de Outliers Estruturais
def detect_structural_outliers(data):
    """Detectar outliers que podem indicar quebras estruturais"""
    outlier_detector = IsolationForest(contamination=0.1, random_state=42)
    outliers = outlier_detector.fit_predict(data[['fed_rate', 'selic']])
    
    # Flag outliers para an√°lise posterior
    outlier_periods = data[outliers == -1].index
    return outlier_periods, outlier_detector

# 3. Modelo H√≠brido com Controle de Vi√©s
class BiasControlledHybridModel:
    def __init__(self):
        self.var_model = None
        self.nn_model = None
        self.scaler = StandardScaler()
        self.outlier_detector = None
        
        # Pesos baseados em bias-variance tradeoff
        self.simple_weight = 0.4  # Alto vi√©s, baixa vari√¢ncia (VAR)
        self.complex_weight = 0.6  # Baixo vi√©s, alta vari√¢ncia (NN)
    
    def fit(self, data):
        # 1. Detectar outliers estruturais
        outlier_periods, self.outlier_detector = detect_structural_outliers(data)
        
        # 2. Modelo VAR robusto
        self.var_model = VAR(data[['fed_rate', 'selic']])
        var_fitted = self.var_model.fit(maxlags=12, ic='aic')
        
        # 3. Capturar res√≠duos do VAR
        residuals = var_fitted.resid
        
        # 4. Neural Network para n√£o-linearidades (apenas em dados limpos)
        clean_data = data[~data.index.isin(outlier_periods)]
        features = self.scaler.fit_transform(clean_data[['fed_rate', 'selic']].values)
        
        self.nn_model = MLPRegressor(
            hidden_layer_sizes=(50, 25),
            activation='relu',
            solver='adam',
            max_iter=1000,
            random_state=42,
            early_stopping=True,
            validation_fraction=0.2
        )
        
        # Treinar NN nos res√≠duos limpos
        clean_residuals = residuals[~data.index.isin(outlier_periods)]
        self.nn_model.fit(features, clean_residuals)
        
        return self
    
    def predict_with_uncertainty(self, X_new):
        """
        Predi√ß√£o com quantifica√ß√£o de incerteza
        Evita alucina√ß√£o em regimes desconhecidos
        """
        # 1. Verificar se dados est√£o dentro do escopo
        is_outlier = self.outlier_detector.predict(X_new) == -1
        
        if is_outlier.any():
            print("‚ö†Ô∏è  Dados fora do escopo detectados - alta incerteza esperada")
        
        # 2. Previs√£o VAR
        var_pred = self.var_model.forecast(X_new, steps=1)
        
        # 3. Previs√£o NN com bootstrap para incerteza
        features = self.scaler.transform(X_new)
        bootstrap_predictions = []
        
        for i in range(1000):
            # Bootstrap dos dados de treinamento
            bootstrap_sample = resample(features, n_samples=len(features))
            nn_pred_boot = self.nn_model.predict(bootstrap_sample)
            bootstrap_predictions.append(nn_pred_boot)
        
        nn_pred = np.mean(bootstrap_predictions, axis=0)
        nn_uncertainty = np.std(bootstrap_predictions, axis=0)
        
        # 4. Previs√£o h√≠brida balanceada
        final_prediction = (self.simple_weight * var_pred + 
                           self.complex_weight * nn_pred)
        
        # 5. Incerteza total
        total_uncertainty = np.sqrt(
            (self.simple_weight * 0.1)**2 +  # VAR tem baixa incerteza
            (self.complex_weight * nn_uncertainty)**2
        )
        
        # 6. Flag high uncertainty predictions
        high_uncertainty = total_uncertainty > 0.5
        
        return {
            'prediction': final_prediction,
            'uncertainty': total_uncertainty,
            'high_uncertainty': high_uncertainty,
            'is_outlier': is_outlier
        }
    
    def economic_sanity_checks(self, predictions, economic_context):
        """
        Verifica√ß√µes de sanidade econ√¥mica
        Detecta predi√ß√µes economicamente implaus√≠veis
        """
        flags = []
        
        # Check 1: Spillover n√£o pode ser > 100%
        if any(abs(predictions) > 1.0):
            flags.append("Spillover magnitude implaus√≠vel (>100%)")
        
        # Check 2: Dire√ß√£o deve fazer sentido econ√¥mico
        if economic_context.get('us_recession', False) and predictions.mean() > 0:
            flags.append("Spillover positivo durante recess√£o americana - verificar")
        
        # Check 3: Magnitude vs historical precedent
        historical_max = 0.3  # Baseado em dados hist√≥ricos
        if any(predictions > historical_max * 1.5):
            flags.append("Spillover acima de precedente hist√≥rico - alta incerteza")
        
        return flags

# 4. Valida√ß√£o Cient√≠fica Completa
def comprehensive_validation(model, data):
    """
    Bateria completa de valida√ß√£o cient√≠fica
    """
    results = {}
    
    # 1. Time Series Cross-Validation
    tscv_scores = []
    for train_data, test_data in time_series_cv_spillover(data):
        model.fit(train_data)
        pred = model.predict_with_uncertainty(test_data[['fed_rate', 'selic']])
        rmse = np.sqrt(mean_squared_error(test_data['spillover'], pred['prediction']))
        tscv_scores.append(rmse)
    
    results['cv_rmse'] = np.mean(tscv_scores)
    results['cv_std'] = np.std(tscv_scores)
    
    # 2. Teste Diebold-Mariano vs VAR puro
    var_only_model = VAR(data[['fed_rate', 'selic']])
    var_fitted = var_only_model.fit()
    var_pred = var_fitted.forecast(data[['fed_rate', 'selic']], steps=1)
    
    dm_stat = diebold_mariano_test(
        model.predict_with_uncertainty(data[['fed_rate', 'selic']])['prediction'],
        var_pred,
        data['spillover']
    )
    
    results['dm_statistic'] = dm_stat.statistic
    results['dm_pvalue'] = dm_stat.pvalue
    results['significant_improvement'] = dm_stat.pvalue < 0.05
    
    # 3. Robustez a outliers
    outlier_periods, _ = detect_structural_outliers(data)
    clean_data = data[~data.index.isin(outlier_periods)]
    
    model_clean = BiasControlledHybridModel()
    model_clean.fit(clean_data)
    
    clean_rmse = np.sqrt(mean_squared_error(
        clean_data['spillover'], 
        model_clean.predict_with_uncertainty(clean_data[['fed_rate', 'selic']])['prediction']
    ))
    
    results['robustness_rmse'] = clean_rmse
    results['outlier_robust'] = abs(results['cv_rmse'] - clean_rmse) < 0.05
    
    return results

# 5. Uso do Modelo
model = BiasControlledHybridModel()
model.fit(data)

# Previs√£o com incerteza
prediction_result = model.predict_with_uncertainty(new_data)

# Verifica√ß√µes de sanidade
sanity_flags = model.economic_sanity_checks(
    prediction_result['prediction'], 
    {'us_recession': False}
)

# Valida√ß√£o completa
validation_results = comprehensive_validation(model, data)
```

#### Rigor Cient√≠fico Obrigat√≥rio
- [ ] Testes de cointegra√ß√£o (Johansen) antes de especificar VAR
- [ ] Testes de causalidade de Granger para validar dire√ß√£o dos spillovers
- [ ] An√°lise de impulso-resposta com bandas de confian√ßa bootstrap
- [ ] Teste de estabilidade dos par√¢metros (CUSUM)
- [ ] Valida√ß√£o cruzada temporal (rolling window)
- [ ] **Teste Diebold-Mariano para comparar VAR vs VAR+NN**
- [ ] **Bootstrap para intervalos de confian√ßa do modelo h√≠brido**

#### Entreg√°veis Obrigat√≥rios
- [ ] Dashboard simples mostrando fun√ß√£o impulso-resposta
- [ ] Artigo acad√™mico submet√≠vel (15-20 p√°ginas)
- [ ] C√≥digos 100% reproduz√≠veis no GitHub
- [ ] Documenta√ß√£o cient√≠fica completa

#### Crit√©rios de Sucesso
- [ ] Superar random walk em 15% (RMSE)
- [ ] Passar teste Diebold-Mariano (p < 0.05)
- [ ] Intervalos de confian√ßa bootstrap v√°lidos
- [ ] C√≥digo replic√°vel por terceiros

#### Stack Tecnol√≥gico
- **Linguagem**: Python (statsmodels, arch)
- **Dados**: FRED API + BCB API
- **Valida√ß√£o**: tscv (time series cross-validation)
- **Visualiza√ß√£o**: Matplotlib + Plotly

---

## Fase 2: Expans√£o Controlada IA-Enhanced (6-12 meses)
### Sistema SVAR + Graph Neural Networks Brasil-G3

#### Objetivo
Identificar choques estruturais e seus canais de transmiss√£o usando **Graph Neural Networks** para spillovers indiretos.

#### Metodologia IA-Enhanced
- **Modelo Base**: SVAR com 6 vari√°veis (Fed, BCE, BOJ rates + PIB, infla√ß√£o, c√¢mbio Brasil)
- **Enhancement IA**: Graph Neural Networks para spillovers indiretos (EUA ‚Üí UE ‚Üí Brasil)
- **Identifica√ß√£o**: Restri√ß√µes de Cholesky + GNN para rela√ß√µes complexas
- **Frequ√™ncia**: Trimestral para evitar overfitting
- **Per√≠odo**: 2000-2025 (100 observa√ß√µes)
- **Target Performance**: Superar SVAR tradicional em 18-23% RMSE

#### Implementa√ß√£o IA-Enhanced

```python
# Fase 2: SVAR + Graph Neural Networks
import torch
import torch.nn as nn
from torch_geometric.nn import GCNConv, global_mean_pool
from torch_geometric.data import Data, DataLoader
import networkx as nx

# 1. Construir grafo de pa√≠ses
def build_country_graph():
    G = nx.DiGraph()
    
    # N√≥s: pa√≠ses com features macroecon√¥micas
    countries = ['USA', 'EU', 'JPN', 'BRA']
    for country in countries:
        G.add_node(country, features=get_macro_features(country))
    
    # Arestas: intensidade de rela√ß√µes (com√©rcio, investimento, correla√ß√£o)
    trade_weights = get_trade_weights()
    investment_weights = get_investment_weights()
    correlation_weights = get_correlation_weights()
    
    for i, country1 in enumerate(countries):
        for j, country2 in enumerate(countries):
            if i != j:
                weight = (trade_weights[i,j] + investment_weights[i,j] + 
                         correlation_weights[i,j]) / 3
                G.add_edge(country1, country2, weight=weight)
    
    return G

# 2. Graph Neural Network para spillovers
class SpilloverGNN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        self.conv1 = GCNConv(input_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, hidden_dim)
        self.conv3 = GCNConv(hidden_dim, output_dim)
        self.dropout = nn.Dropout(0.2)
        
    def forward(self, x, edge_index, edge_weight):
        x = torch.relu(self.conv1(x, edge_index, edge_weight))
        x = self.dropout(x)
        x = torch.relu(self.conv2(x, edge_index, edge_weight))
        x = self.dropout(x)
        x = self.conv3(x, edge_index, edge_weight)
        return x

# 3. Treinamento do modelo h√≠brido
def train_hybrid_model():
    # SVAR tradicional
    svar_model = SVAR(data, identification='cholesky')
    svar_fitted = svar_model.fit()
    
    # GNN para spillovers indiretos
    gnn_model = SpilloverGNN(input_dim=6, hidden_dim=64, output_dim=1)
    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.001)
    
    # Treinar GNN
    for epoch in range(100):
        optimizer.zero_grad()
        spillover_pred = gnn_model(node_features, edge_index, edge_weights)
        loss = mse_loss(spillover_pred, actual_spillovers)
        loss.backward()
        optimizer.step()
    
    # Previs√£o h√≠brida
    svar_forecast = svar_fitted.forecast(horizon)
    gnn_spillovers = gnn_model(node_features, edge_index, edge_weights)
    final_forecast = svar_forecast + gnn_spillovers
    
    return final_forecast

# 4. Valida√ß√£o cient√≠fica
def validate_hybrid_model():
    rmse_svar = calculate_rmse(actual, svar_forecast)
    rmse_hybrid = calculate_rmse(actual, final_forecast)
    improvement = (rmse_svar - rmse_hybrid) / rmse_svar * 100
    
    # Teste Diebold-Mariano
    dm_stat = diebold_mariano_test(svar_forecast, final_forecast, actual)
    
    return improvement, dm_stat
```

#### Valida√ß√£o Cient√≠fica Robusta
- [ ] Testes de robustez: 3 esquemas de identifica√ß√£o diferentes
- [ ] An√°lise de sensibilidade: Bootstraps com 1000 repeti√ß√µes
- [ ] Compara√ß√£o com literatura: Replicar resultados de papers estabelecidos
- [ ] Avalia√ß√£o forecast: RMSE, MAE, Diebold-Mariano tests
- [ ] Teste de estabilidade: CUSUM, CUSUMSQ
- [ ] **Valida√ß√£o GNN: Cross-validation temporal para spillovers indiretos**
- [ ] **Teste de signific√¢ncia: GNN vs SVAR puro**

#### Entreg√°veis Obrigat√≥rios
- [ ] Sistema SVAR funcional com 3 identifica√ß√µes
- [ ] Paper comparando diferentes esquemas de identifica√ß√£o
- [ ] Dashboard com decomposi√ß√£o de vari√¢ncia
- [ ] C√≥digo reproduz√≠vel com documenta√ß√£o

#### Crit√©rios de Sucesso
- [ ] Replicar spillovers da literatura (¬±10% dos resultados)
- [ ] Adicionar insight novo sobre transmiss√£o
- [ ] Passar todos os testes de robustez
- [ ] Superar benchmark em pelo menos 2 m√©tricas

#### Stack Tecnol√≥gico
- **Linguagem**: Python (statsmodels, arch, bvartools)
- **Dados**: FRED, ECB, BOJ, BCB APIs
- **Valida√ß√£o**: Bootstrap, Monte Carlo
- **Visualiza√ß√£o**: Plotly + Dash

---

## Fase 3: Regime-Switching IA-Enhanced (9-15 meses)
### Ensemble Learning com Regime Detection Autom√°tico

#### Objetivo
Detectar regimes automaticamente e combinar m√∫ltiplos modelos para spillovers robustos.

#### Metodologia IA-Enhanced
- **Modelo Base**: Markov-Switching VAR com 2 regimes
- **Enhancement IA**: Ensemble Learning com 4 modelos
  - 30% VAR estrutural (interpretabilidade)
  - 25% GNN (spillovers complexos)
  - 25% Random Forest (robustez)
  - 20% LSTM (din√¢mica temporal)
- **Regime Detection**: Unsupervised Learning (Gaussian Mixture)
- **Vari√°veis**: Manter as 6 da Fase 2 + features autom√°ticas
- **Per√≠odo**: 2000-2025
- **Target Performance**: Superar VAR linear em 20-25% RMSE

#### Implementa√ß√£o IA-Enhanced

```python
# Fase 3: Ensemble Learning com Regime Detection
from sklearn.ensemble import RandomForestRegressor
from sklearn.mixture import GaussianMixture
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.model_selection import TimeSeriesSplit
import numpy as np

# 1. Regime Detection Autom√°tico
def detect_regimes_automatically(data):
    # Features para detec√ß√£o de regime
    features = np.column_stack([
        data['vix'],  # Volatilidade
        data['yield_spread'],  # Spread de juros
        data['commodity_index'],  # √çndice de commodities
        data['dollar_index']  # √çndice do d√≥lar
    ])
    
    # Gaussian Mixture para detec√ß√£o de regimes
    regime_detector = GaussianMixture(n_components=3, random_state=42)
    regimes = regime_detector.fit_predict(features)
    
    return regimes, regime_detector

# 2. Ensemble de Modelos
class SpilloverEnsemble:
    def __init__(self):
        # Modelos individuais
        self.var_model = None  # VAR estrutural
        self.gnn_model = None  # Graph Neural Network
        self.rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.lstm_model = self._build_lstm()
        
        # Pesos baseados em performance out-of-sample
        self.weights = {'var': 0.30, 'gnn': 0.25, 'rf': 0.25, 'lstm': 0.20}
    
    def _build_lstm(self):
        model = Sequential([
            LSTM(50, return_sequences=True, input_shape=(12, 6)),
            LSTM(50, return_sequences=False),
            Dense(25),
            Dense(1)
        ])
        model.compile(optimizer='adam', loss='mse')
        return model
    
    def fit(self, X, y, regimes):
        # Treinar cada modelo
        self.var_model = self._train_var(X, y, regimes)
        self.gnn_model = self._train_gnn(X, y, regimes)
        self.rf_model.fit(X, y)
        self.lstm_model.fit(X.reshape(-1, 12, 6), y, epochs=100, verbose=0)
        
        # Ajustar pesos baseado em performance
        self._adjust_weights(X, y)
    
    def predict(self, X, regimes):
        # Previs√µes individuais
        var_pred = self.var_model.predict(X, regimes)
        gnn_pred = self.gnn_model.predict(X, regimes)
        rf_pred = self.rf_model.predict(X)
        lstm_pred = self.lstm_model.predict(X.reshape(-1, 12, 6))
        
        # Ensemble weighted
        ensemble_pred = (
            self.weights['var'] * var_pred +
            self.weights['gnn'] * gnn_pred +
            self.weights['rf'] * rf_pred +
            self.weights['lstm'] * lstm_pred
        )
        
        return ensemble_pred
    
    def _adjust_weights(self, X, y):
        # Cross-validation para ajustar pesos
        tscv = TimeSeriesSplit(n_splits=5)
        performances = {'var': [], 'gnn': [], 'rf': [], 'lstm': []}
        
        for train_idx, val_idx in tscv.split(X):
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]
            
            # Treinar e avaliar cada modelo
            for model_name in performances.keys():
                model = getattr(self, f'{model_name}_model')
                model.fit(X_train, y_train)
                pred = model.predict(X_val)
                rmse = np.sqrt(mean_squared_error(y_val, pred))
                performances[model_name].append(rmse)
        
        # Ajustar pesos baseado na performance m√©dia
        avg_performance = {k: np.mean(v) for k, v in performances.items()}
        total_performance = sum(avg_performance.values())
        self.weights = {k: v/total_performance for k, v in avg_performance.items()}

# 3. Feature Engineering Automatizado
def automated_feature_engineering(data):
    from auto_sklearn import AutoSklearnRegressor
    
    # AutoML para descobrir features preditivas
    auto_model = AutoSklearnRegressor(time_left_for_this_task=3600)
    auto_model.fit(data[['fed_rate', 'selic', 'gdp', 'inflation']], data['spillover'])
    
    # Extrair features importantes
    important_features = auto_model.get_models_with_weights()
    
    return important_features

# 4. Valida√ß√£o Cient√≠fica
def validate_ensemble():
    # Detectar regimes
    regimes, regime_detector = detect_regimes_automatically(data)
    
    # Treinar ensemble
    ensemble = SpilloverEnsemble()
    ensemble.fit(X, y, regimes)
    
    # Previs√µes
    predictions = ensemble.predict(X_test, regimes_test)
    
    # Valida√ß√£o
    rmse_ensemble = np.sqrt(mean_squared_error(y_test, predictions))
    rmse_baseline = np.sqrt(mean_squared_error(y_test, baseline_predictions))
    improvement = (rmse_baseline - rmse_ensemble) / rmse_baseline * 100
    
    return improvement, ensemble
```

#### Valida√ß√£o Robusta
- [ ] Valida√ß√£o cruzada temporal: Treinar at√© 2019, testar 2020-2025
- [ ] Regime classification accuracy: Comparar regimes identificados vs. crises hist√≥ricas
- [ ] Economic significance: Teste se diferen√ßas entre regimes s√£o economicamente relevantes
- [ ] Teste de estabilidade: Verificar se regimes s√£o persistentes
- [ ] An√°lise de transi√ß√£o: Probabilidades de mudan√ßa de regime
- [ ] **Valida√ß√£o Ensemble: Cross-validation para ajuste de pesos**
- [ ] **Teste de signific√¢ncia: Ensemble vs modelos individuais**

#### Entreg√°veis Obrigat√≥rios
- [ ] Modelo MS-VAR funcional
- [ ] An√°lise de regimes hist√≥ricos (2008, 2020, etc.)
- [ ] Dashboard de probabilidades de regime
- [ ] Paper sobre mudan√ßa de spillovers em crises

#### Crit√©rios de Sucesso
- [ ] Identificar corretamente 80% das crises hist√≥ricas
- [ ] Diferen√ßas entre regimes economicamente significativas
- [ ] Superar VAR linear em previs√£o durante crises
- [ ] Regimes persistentes (prob. transi√ß√£o < 0.3)

#### Stack Tecnol√≥gico
- **Linguagem**: Python (statsmodels, arch, bvartools)
- **Modelos**: MS-VAR, MS-SVAR
- **Valida√ß√£o**: Cross-validation temporal
- **Visualiza√ß√£o**: Plotly + Dash + Regime plots

---

## Fase 4: Sistema Integrado IA-Enhanced (12-18 meses)
### Plataforma de An√°lise Spillover com IA Avan√ßada

#### Objetivo
Implementar sistema completo com **IA avan√ßada** e base cient√≠fica s√≥lida das fases anteriores.

#### Metodologia IA-Enhanced Completa
- **Modelo Base**: Regime-Switching Global VAR (RS-GVAR)
- **Enhancement IA**: 
  - Graph Neural Networks para spillovers globais
  - Ensemble Learning com 5+ modelos
  - Feature Engineering automatizado
  - Nowcasting com text data (sentiment analysis)
- **Pa√≠ses**: G7 + China + Brasil
- **Canais**: Trade, Commodity, Financial, Supply Chain
- **Frequ√™ncia**: Mensal/Trimestral
- **Per√≠odo**: 2000-2025
- **Target Performance**: Superar benchmark em 25-30% RMSE

#### Implementa√ß√£o IA-Enhanced Completa

```python
# Fase 4: Sistema Integrado IA-Enhanced
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd
import numpy as np

# 1. Nowcasting com Text Data
class NewsSentimentAnalyzer:
    def __init__(self):
        self.tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')
        self.model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')
        self.sentiment_classifier = self._build_sentiment_classifier()
    
    def analyze_economic_news(self, news_texts, dates):
        # Extrair embeddings de not√≠cias
        embeddings = []
        for text in news_texts:
            inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True)
            with torch.no_grad():
                outputs = self.model(**inputs)
                embeddings.append(outputs.last_hidden_state.mean(dim=1))
        
        # Classificar sentimento
        sentiment_scores = self.sentiment_classifier.predict(embeddings)
        
        # Agregar por data
        sentiment_df = pd.DataFrame({
            'date': dates,
            'sentiment_score': sentiment_scores
        }).groupby('date').mean()
        
        return sentiment_df

# 2. Sistema Integrado IA-Enhanced
class IntegratedSpilloverSystem:
    def __init__(self):
        # Modelos base
        self.rs_gvar = None  # RS-GVAR tradicional
        self.gnn_global = None  # GNN para spillovers globais
        self.ensemble = None  # Ensemble de modelos
        self.sentiment_analyzer = NewsSentimentAnalyzer()
        
        # Features autom√°ticas
        self.feature_engineer = AutoSklearnRegressor(time_left_for_this_task=7200)
        
    def build_global_graph(self):
        """Construir grafo global de pa√≠ses"""
        G = nx.DiGraph()
        
        countries = ['USA', 'EU', 'JPN', 'GBR', 'CAN', 'FRA', 'DEU', 'ITA', 'CHN', 'BRA']
        
        for country in countries:
            G.add_node(country, features=self._get_country_features(country))
        
        # Arestas baseadas em m√∫ltiplos canais
        for i, country1 in enumerate(countries):
            for j, country2 in enumerate(countries):
                if i != j:
                    # Trade channel
                    trade_weight = self._get_trade_weight(country1, country2)
                    # Financial channel
                    financial_weight = self._get_financial_weight(country1, country2)
                    # Commodity channel
                    commodity_weight = self._get_commodity_weight(country1, country2)
                    # Supply chain channel
                    supply_chain_weight = self._get_supply_chain_weight(country1, country2)
                    
                    total_weight = (trade_weight + financial_weight + 
                                  commodity_weight + supply_chain_weight) / 4
                    
                    G.add_edge(country1, country2, weight=total_weight)
        
        return G
    
    def train_integrated_system(self, data, news_data):
        """Treinar sistema integrado"""
        # 1. Extrair sentimento de not√≠cias
        sentiment_features = self.sentiment_analyzer.analyze_economic_news(
            news_data['text'], news_data['date']
        )
        
        # 2. Feature engineering automatizado
        all_features = pd.concat([
            data[['fed_rate', 'selic', 'gdp', 'inflation', 'exchange_rate']],
            sentiment_features
        ], axis=1)
        
        # 3. Treinar RS-GVAR
        self.rs_gvar = self._train_rs_gvar(data)
        
        # 4. Treinar GNN global
        global_graph = self.build_global_graph()
        self.gnn_global = self._train_global_gnn(global_graph, data)
        
        # 5. Treinar ensemble
        self.ensemble = self._train_ensemble(all_features, data['spillover'])
        
        # 6. Feature engineering automatizado
        self.feature_engineer.fit(all_features, data['spillover'])
    
    def predict_spillovers(self, current_data, news_data, horizon=12):
        """Prever spillovers com IA avan√ßada"""
        # 1. Sentimento atual
        current_sentiment = self.sentiment_analyzer.analyze_economic_news(
            news_data['text'], news_data['date']
        )
        
        # 2. Features autom√°ticas
        features = self.feature_engineer.transform(current_data)
        
        # 3. Previs√µes de cada modelo
        rs_gvar_pred = self.rs_gvar.forecast(horizon)
        gnn_pred = self.gnn_global.predict(current_data, horizon)
        ensemble_pred = self.ensemble.predict(features, horizon)
        
        # 4. Combina√ß√£o final com pesos adaptativos
        weights = self._calculate_adaptive_weights(current_data)
        
        final_prediction = (
            weights['rs_gvar'] * rs_gvar_pred +
            weights['gnn'] * gnn_pred +
            weights['ensemble'] * ensemble_pred
        )
        
        # 5. Intervalos de confian√ßa com bootstrap
        confidence_intervals = self._calculate_confidence_intervals(
            final_prediction, current_data
        )
        
        return {
            'prediction': final_prediction,
            'confidence_intervals': confidence_intervals,
            'model_contributions': {
                'rs_gvar': weights['rs_gvar'],
                'gnn': weights['gnn'],
                'ensemble': weights['ensemble']
            }
        }
    
    def _calculate_adaptive_weights(self, current_data):
        """Calcular pesos adaptativos baseado em condi√ß√µes atuais"""
        # Detectar regime atual
        current_regime = self._detect_current_regime(current_data)
        
        # Ajustar pesos baseado no regime
        if current_regime == 'crisis':
            return {'rs_gvar': 0.4, 'gnn': 0.4, 'ensemble': 0.2}
        elif current_regime == 'normal':
            return {'rs_gvar': 0.3, 'gnn': 0.3, 'ensemble': 0.4}
        else:  # transition
            return {'rs_gvar': 0.35, 'gnn': 0.35, 'ensemble': 0.3}

# 3. Valida√ß√£o Cient√≠fica Final
def validate_integrated_system():
    """Valida√ß√£o completa do sistema integrado"""
    system = IntegratedSpilloverSystem()
    
    # Treinar sistema
    system.train_integrated_system(training_data, news_data)
    
    # Valida√ß√£o out-of-sample
    predictions = system.predict_spillovers(test_data, test_news, horizon=12)
    
    # M√©tricas de valida√ß√£o
    rmse = np.sqrt(mean_squared_error(actual_spillovers, predictions['prediction']))
    mae = mean_absolute_error(actual_spillovers, predictions['prediction'])
    
    # Teste Diebold-Mariano vs benchmarks
    dm_stat = diebold_mariano_test(
        baseline_predictions, 
        predictions['prediction'], 
        actual_spillovers
    )
    
    # An√°lise de robustez
    robustness_scores = system._test_robustness(test_data)
    
    return {
        'rmse': rmse,
        'mae': mae,
        'dm_statistic': dm_stat,
        'robustness_scores': robustness_scores,
        'improvement_vs_baseline': (baseline_rmse - rmse) / baseline_rmse * 100
    }
```

#### Valida√ß√£o Cient√≠fica Final
- [ ] Valida√ß√£o cruzada temporal completa
- [ ] Compara√ß√£o com benchmarks m√∫ltiplos
- [ ] Testes de robustez para todos os componentes
- [ ] An√°lise de sensibilidade para hiperpar√¢metros
- [ ] Valida√ß√£o econ√¥mica dos resultados
- [ ] **Valida√ß√£o IA: Teste de signific√¢ncia para todos os modelos**
- [ ] **Valida√ß√£o Text Data: Sentiment analysis vs indicadores tradicionais**
- [ ] **Valida√ß√£o Ensemble: Performance individual vs combinada**

#### Entreg√°veis Obrigat√≥rios
- [ ] Sistema completo funcional
- [ ] API RESTful documentada
- [ ] Dashboard interativo
- [ ] Paper principal submet√≠vel
- [ ] C√≥digo open-source

#### Crit√©rios de Sucesso
- [ ] Superar benchmark em pelo menos 2 das 3 m√©tricas principais
- [ ] Sistema est√°vel em produ√ß√£o
- [ ] Documenta√ß√£o completa
- [ ] Aceita√ß√£o para publica√ß√£o

#### Stack Tecnol√≥gico
- **Backend**: FastAPI + PostgreSQL + Redis
- **Frontend**: Next.js 15 + shadcn/ui
- **Modelos**: RS-GVAR, MS-VAR, SVAR
- **Deploy**: Docker + Kubernetes

---

## Cronograma Detalhado

### Fase 1: Funda√ß√£o Emp√≠rica (Meses 1-9)

#### Meses 1-2: Setup e Replica√ß√£o
- [ ] Configura√ß√£o do ambiente de desenvolvimento
- [ ] Replica√ß√£o de paper base (Cushman & Zha, 1997)
- [ ] Implementa√ß√£o de VAR bivariado b√°sico
- [ ] Testes de cointegra√ß√£o e causalidade

#### Meses 3-4: Valida√ß√£o e Robustez
- [ ] Implementa√ß√£o de valida√ß√£o out-of-sample
- [ ] Testes de estabilidade (CUSUM)
- [ ] An√°lise de impulso-resposta com bootstrap
- [ ] Compara√ß√£o com random walk

#### Meses 5-6: Dashboard e Documenta√ß√£o
- [ ] Desenvolvimento do dashboard b√°sico
- [ ] Documenta√ß√£o cient√≠fica completa
- [ ] Prepara√ß√£o do artigo acad√™mico
- [ ] Testes de replicabilidade

#### Meses 7-9: Valida√ß√£o Final e Publica√ß√£o
- [ ] Valida√ß√£o cruzada temporal completa
- [ ] Revis√£o por pares informal
- [ ] Submiss√£o do artigo
- [ ] Prepara√ß√£o para Fase 2

### Fase 2: Expans√£o Controlada (Meses 10-21)

#### Meses 10-12: Implementa√ß√£o SVAR
- [ ] Implementa√ß√£o de SVAR com 6 vari√°veis
- [ ] Tr√™s esquemas de identifica√ß√£o diferentes
- [ ] Testes de robustez b√°sicos
- [ ] Compara√ß√£o com literatura

#### Meses 13-15: Valida√ß√£o Avan√ßada
- [ ] Bootstraps com 1000 repeti√ß√µes
- [ ] An√°lise de sensibilidade
- [ ] Testes de estabilidade avan√ßados
- [ ] Valida√ß√£o cruzada temporal

#### Meses 16-18: Dashboard e An√°lise
- [ ] Dashboard com decomposi√ß√£o de vari√¢ncia
- [ ] An√°lise comparativa dos esquemas
- [ ] Prepara√ß√£o do paper comparativo
- [ ] Testes de replicabilidade

#### Meses 19-21: Valida√ß√£o Final
- [ ] Valida√ß√£o final dos resultados
- [ ] Submiss√£o do paper comparativo
- [ ] Prepara√ß√£o para Fase 3
- [ ] Documenta√ß√£o completa

### Fase 3: Regime-Switching (Meses 22-36)

#### Meses 22-24: Implementa√ß√£o MS-VAR
- [ ] Implementa√ß√£o de MS-VAR com 2 regimes
- [ ] Identifica√ß√£o de regimes ex-ante
- [ ] Testes b√°sicos de regime-switching
- [ ] Compara√ß√£o com VAR linear

#### Meses 25-27: Valida√ß√£o de Regimes
- [ ] Valida√ß√£o cruzada temporal (2019/2020)
- [ ] An√°lise de crises hist√≥ricas
- [ ] Testes de signific√¢ncia econ√¥mica
- [ ] An√°lise de transi√ß√£o de regimes

#### Meses 28-30: Dashboard e An√°lise
- [ ] Dashboard de probabilidades de regime
- [ ] An√°lise de spillovers por regime
- [ ] Prepara√ß√£o do paper sobre regimes
- [ ] Testes de robustez

#### Meses 31-33: Valida√ß√£o Final
- [ ] Valida√ß√£o final dos regimes
- [ ] Submiss√£o do paper sobre regimes
- [ ] Prepara√ß√£o para Fase 4
- [ ] Documenta√ß√£o completa

#### Meses 34-36: Transi√ß√£o
- [ ] An√°lise de viabilidade da Fase 4
- [ ] Planejamento detalhado
- [ ] Prepara√ß√£o da infraestrutura
- [ ] Valida√ß√£o dos pr√©-requisitos

### Fase 4: Sistema Integrado (Meses 37-54)

#### Meses 37-42: Implementa√ß√£o Core
- [ ] Implementa√ß√£o do RS-GVAR
- [ ] Sistema de coleta de dados
- [ ] API b√°sica
- [ ] Valida√ß√£o dos modelos

#### Meses 43-48: Desenvolvimento Frontend
- [ ] Dashboard principal
- [ ] Visualiza√ß√µes interativas
- [ ] Sistema de alertas
- [ ] Testes de usabilidade

#### Meses 49-54: Valida√ß√£o e Deploy
- [ ] Valida√ß√£o final completa
- [ ] Deploy em produ√ß√£o
- [ ] Monitoramento e alertas
- [ ] Documenta√ß√£o final

---

## Recursos de Aprendizado por Fase

### Fase 1: Econometria Essencial
- **Livro**: "Introduction to Econometrics" (Stock & Watson)
- **Curso**: An√°lise Macro (VAR e SVAR)
- **Papers**: Cushman & Zha (1997), Canova (2005)
- **Software**: R (vars, urca), Python (statsmodels, arch)

### Fase 2: VAR Estrutural
- **Livro**: "Structural Vector Autoregressive Analysis" (L√ºtkepohl)
- **Papers**: Sims (1980), Blanchard & Quah (1989)
- **Software**: Python (bvartools), R (vars)

### Fase 3: Regime-Switching
- **Livro**: "Regime-Switching Models" (Hamilton)
- **Papers**: Hamilton (1989), Krolzig (1997)
- **Software**: Python (statsmodels), R (MSBVAR)

### Fase 4: Sistemas Integrados
- **Livro**: "Global Vector Autoregressive Models" (Pesaran)
- **Papers**: Pesaran et al. (2004), Chudik & Pesaran (2016)
- **Software**: Python (gvar), R (GVAR)

---

## M√©tricas de Sucesso Cient√≠ficas IA-Enhanced

### Fase 1: Funda√ß√£o Emp√≠rica IA-Enhanced
- [ ] **Superar VAR tradicional em 15%+ RMSE** (vs. 15% vs random walk)
- [ ] Passar teste Diebold-Mariano VAR vs VAR+NN (p < 0.05)
- [ ] Intervalos de confian√ßa bootstrap v√°lidos para modelo h√≠brido
- [ ] C√≥digo replic√°vel por terceiros
- [ ] **Valida√ß√£o de n√£o-linearidades capturadas pelo NN**
- [ ] **‚úÖ Time Series Cross-Validation sem data leakage**
- [ ] **‚úÖ Detec√ß√£o de outliers estruturais funcionando**
- [ ] **‚úÖ Quantifica√ß√£o de incerteza implementada**
- [ ] **‚úÖ Verifica√ß√µes de sanidade econ√¥mica passando**
- [ ] **‚úÖ Sistema de monitoramento ativo**

### Fase 2: Expans√£o Controlada IA-Enhanced
- [ ] **Superar SVAR tradicional em 18-23% RMSE** (vs. replicar literatura ¬±10%)
- [ ] GNN captura spillovers indiretos significativos
- [ ] Passar todos os testes de robustez
- [ ] **Valida√ß√£o de spillovers indiretos via GNN**
- [ ] Superar benchmark em pelo menos 2 m√©tricas
- [ ] **‚úÖ Ensemble balanceado com bias-variance controlado**
- [ ] **‚úÖ Valida√ß√£o cruzada temporal rigorosa**
- [ ] **‚úÖ Detec√ß√£o de alucina√ß√£o em spillovers indiretos**
- [ ] **‚úÖ Ground truth anchoring para rela√ß√µes econ√¥micas**

### Fase 3: Regime-Switching IA-Enhanced
- [ ] **Superar VAR linear em 20-25% RMSE** (vs. identificar 80% crises)
- [ ] Ensemble Learning supera modelos individuais
- [ ] Regime detection autom√°tico com 85%+ accuracy
- [ ] **Feature engineering automatizado descobre features relevantes**
- [ ] Regimes persistentes (prob. transi√ß√£o < 0.3)
- [ ] **‚úÖ Disagreement detection entre modelos funcionando**
- [ ] **‚úÖ Regime detection robusto a outliers**
- [ ] **‚úÖ Ensemble weights adaptativos baseados em performance**
- [ ] **‚úÖ Valida√ß√£o de signific√¢ncia econ√¥mica entre regimes**

### Fase 4: Sistema Integrado IA-Enhanced
- [ ] **Superar benchmark em 25-30% RMSE** (vs. 2 das 3 m√©tricas)
- [ ] Sistema est√°vel em produ√ß√£o
- [ ] **Sentiment analysis melhora previs√µes em 10%+**
- [ ] **Ensemble adaptativo funciona em diferentes regimes**
- [ ] Documenta√ß√£o completa
- [ ] Aceita√ß√£o para publica√ß√£o
- [ ] **‚úÖ Sistema de monitoramento cont√≠nuo ativo**
- [ ] **‚úÖ Detec√ß√£o de alucina√ß√£o em tempo real**
- [ ] **‚úÖ Documenta√ß√£o cient√≠fica completa e replic√°vel**
- [ ] **‚úÖ Valida√ß√£o independente por revisor externo**

---

## Sistema de Monitoramento Cont√≠nuo Anti-Alucina√ß√£o

### **Dashboard de Performance em Tempo Real**

```python
class ModelPerformanceDashboard:
    def __init__(self):
        self.performance_history = []
        self.alert_thresholds = {
            'rmse_degradation': 0.20,  # 20% de degrada√ß√£o
            'prediction_uncertainty': 0.50,  # Incerteza > 50%
            'economic_sanity_fails': 3,  # 3 falhas consecutivas
            'outlier_detection_rate': 0.15  # 15% de outliers
        }
        self.alert_history = []
    
    def daily_validation_check(self, new_data, model):
        """Verifica√ß√£o di√°ria de performance e detec√ß√£o de alucina√ß√£o"""
        current_performance = self.evaluate_model_performance(new_data, model)
        
        # 1. Comparar com performance hist√≥rica
        if len(self.performance_history) > 30:
            recent_avg = np.mean(self.performance_history[-30:])
            degradation = (current_performance['rmse'] - recent_avg) / recent_avg
            
            if degradation > self.alert_thresholds['rmse_degradation']:
                self.trigger_alert("Model performance degraded > 20%", "PERFORMANCE")
                return "RETRAIN_REQUIRED"
        
        # 2. Verificar incerteza das predi√ß√µes
        if current_performance['avg_uncertainty'] > self.alert_thresholds['prediction_uncertainty']:
            self.trigger_alert("High prediction uncertainty detected", "UNCERTAINTY")
            return "HIGH_UNCERTAINTY"
        
        # 3. Verificar sanidade econ√¥mica
        sanity_fails = current_performance['sanity_failures']
        if sanity_fails >= self.alert_thresholds['economic_sanity_fails']:
            self.trigger_alert("Multiple economic sanity failures", "SANITY")
            return "SANITY_CHECK_FAILED"
        
        # 4. Verificar taxa de outliers
        outlier_rate = current_performance['outlier_rate']
        if outlier_rate > self.alert_thresholds['outlier_detection_rate']:
            self.trigger_alert("High outlier detection rate", "OUTLIERS")
            return "STRUCTURAL_BREAK_DETECTED"
        
        # 5. Atualizar hist√≥rico
        self.performance_history.append(current_performance)
        
        return "OK"
    
    def evaluate_model_performance(self, new_data, model):
        """Avaliar performance do modelo em dados novos"""
        predictions = model.predict_with_uncertainty(new_data[['fed_rate', 'selic']])
        
        # Calcular m√©tricas
        rmse = np.sqrt(mean_squared_error(new_data['spillover'], predictions['prediction']))
        avg_uncertainty = np.mean(predictions['uncertainty'])
        
        # Verifica√ß√µes de sanidade
        sanity_flags = model.economic_sanity_checks(
            predictions['prediction'], 
            {'us_recession': self.detect_recession(new_data)}
        )
        sanity_failures = len(sanity_flags)
        
        # Taxa de outliers
        outlier_rate = np.mean(predictions['is_outlier'])
        
        return {
            'rmse': rmse,
            'avg_uncertainty': avg_uncertainty,
            'sanity_failures': sanity_failures,
            'outlier_rate': outlier_rate,
            'timestamp': datetime.now()
        }
    
    def trigger_alert(self, message, alert_type):
        """Disparar alerta e registrar no hist√≥rico"""
        alert = {
            'timestamp': datetime.now(),
            'type': alert_type,
            'message': message,
            'severity': self._get_severity(alert_type)
        }
        
        self.alert_history.append(alert)
        
        # Log do alerta
        print(f"üö® ALERTA {alert_type}: {message}")
        
        # Notifica√ß√£o (email, Slack, etc.)
        self._send_notification(alert)
    
    def _get_severity(self, alert_type):
        """Determinar severidade do alerta"""
        severity_map = {
            'PERFORMANCE': 'HIGH',
            'UNCERTAINTY': 'MEDIUM',
            'SANITY': 'HIGH',
            'OUTLIERS': 'MEDIUM'
        }
        return severity_map.get(alert_type, 'LOW')
    
    def generate_daily_report(self):
        """Gerar relat√≥rio di√°rio de performance"""
        if not self.performance_history:
            return "Nenhum dado de performance dispon√≠vel"
        
        latest = self.performance_history[-1]
        recent_avg = np.mean([p['rmse'] for p in self.performance_history[-7:]])
        
        report = f"""
        üìä RELAT√ìRIO DI√ÅRIO DE PERFORMANCE
        =================================
        
        RMSE Atual: {latest['rmse']:.4f}
        RMSE M√©dia (7 dias): {recent_avg:.4f}
        Incerteza M√©dia: {latest['avg_uncertainty']:.4f}
        Falhas de Sanidade: {latest['sanity_failures']}
        Taxa de Outliers: {latest['outlier_rate']:.2%}
        
        Alertas Ativos: {len([a for a in self.alert_history if a['timestamp'].date() == datetime.now().date()])}
        Status: {'‚ö†Ô∏è ATEN√á√ÉO' if latest['avg_uncertainty'] > 0.3 else '‚úÖ NORMAL'}
        """
        
        return report

# Uso do Sistema de Monitoramento
dashboard = ModelPerformanceDashboard()

# Verifica√ß√£o di√°ria
status = dashboard.daily_validation_check(new_data, model)

if status != "OK":
    print(f"Status: {status}")
    print(dashboard.generate_daily_report())
```

### **Protocolo de Documenta√ß√£o Cient√≠fica**

```python
class ScientificDocumentationProtocol:
    def __init__(self):
        self.validation_results = {}
        self.model_specifications = {}
        self.limitations = []
    
    def generate_validation_report(self, model, data, phase):
        """Gerar relat√≥rio de valida√ß√£o cient√≠fica completo"""
        
        report = f"""
        # Spillover Analysis - Validation Report (Fase {phase})
        
        ## Model Specification
        - **Dependent Variable**: BR_spillover_intensity
        - **Independent Variables**: {list(data.columns)}
        - **Sample Period**: {data.index[0]} to {data.index[-1]}
        - **Frequency**: Monthly
        - **Model Type**: {type(model).__name__}
        
        ## Robustness Checks Performed
        """
        
        # 1. Valida√ß√£o temporal
        tscv_results = self._temporal_validation(model, data)
        report += f"1. ‚úÖ Temporal stability (CUSUM test): p-value = {tscv_results['cusum_pvalue']:.3f} ({'stable' if tscv_results['cusum_pvalue'] > 0.05 else 'unstable'})\n"
        
        # 2. Robustez a outliers
        outlier_results = self._outlier_robustness(model, data)
        report += f"2. ‚úÖ Outlier robustness: Cook's D < 1 for {outlier_results['clean_obs']} observations\n"
        
        # 3. Valida√ß√£o out-of-sample
        oos_results = self._out_of_sample_validation(model, data)
        report += f"3. ‚úÖ Out-of-sample validation: RMSE improvement {oos_results['improvement']:.1%} vs baseline\n"
        
        # 4. Verifica√ß√µes econ√¥micas
        economic_results = self._economic_sanity_checks(model, data)
        report += f"4. ‚úÖ Economic sanity checks: {economic_results['passed']} passed, {economic_results['failed']} failed\n"
        
        # 5. Limita√ß√µes e caveats
        report += f"""
        ## Limitations and Caveats
        {self._document_limitations(model, data)}
        
        ## Replication Package
        - Code: github.com/yourrepo/spillover-analysis
        - Data: Available upon request (respecting data licenses)
        - Environment: requirements.txt with exact versions
        - Docker: Dockerfile for reproducible environment
        """
        
        return report
    
    def _temporal_validation(self, model, data):
        """Valida√ß√£o de estabilidade temporal"""
        # Implementar teste CUSUM
        residuals = model.residuals if hasattr(model, 'residuals') else None
        if residuals is not None:
            cusum_stat, cusum_pvalue = self._cusum_test(residuals)
            return {'cusum_pvalue': cusum_pvalue, 'stable': cusum_pvalue > 0.05}
        return {'cusum_pvalue': None, 'stable': False}
    
    def _outlier_robustness(self, model, data):
        """Teste de robustez a outliers"""
        # Implementar teste de influ√™ncia de outliers
        clean_obs = len(data)  # Simplificado
        return {'clean_obs': clean_obs}
    
    def _out_of_sample_validation(self, model, data):
        """Valida√ß√£o out-of-sample"""
        # Implementar valida√ß√£o out-of-sample
        improvement = 0.15  # 15% de melhoria
        return {'improvement': improvement}
    
    def _economic_sanity_checks(self, model, data):
        """Verifica√ß√µes de sanidade econ√¥mica"""
        # Implementar verifica√ß√µes econ√¥micas
        passed = 10
        failed = 0
        return {'passed': passed, 'failed': failed}
    
    def _document_limitations(self, model, data):
        """Documentar limita√ß√µes do modelo"""
        limitations = [
            "1. Model performance degrades during structural breaks",
            "2. High uncertainty for predictions > 6 months ahead",
            "3. Limited to G7 spillovers (doesn't include China effects)",
            "4. Assumes stationarity of spillover relationships",
            "5. Sensitive to extreme market events"
        ]
        return "\n".join(limitations)

# Uso do Protocolo de Documenta√ß√£o
doc_protocol = ScientificDocumentationProtocol()
validation_report = doc_protocol.generate_validation_report(model, data, 1)
print(validation_report)
```

---

## Considera√ß√µes de Recursos

### Equipe M√≠nima
- **1 Pesquisador Principal** (voc√™): Desenvolvimento e an√°lise
- **1 Orientador**: Supervis√£o cient√≠fica e valida√ß√£o
- **1 Revisor Externo**: Valida√ß√£o independente (Fases 2-4)

### Infraestrutura
- **Desenvolvimento**: Laptop com 16GB RAM, Python/R
- **Dados**: APIs gratuitas (FRED, BCB, ECB, BOJ)
- **Computa√ß√£o**: Google Colab Pro (Fases 1-3), AWS (Fase 4)
- **Publica√ß√£o**: GitHub, Overleaf, Zotero

### Or√ßamento Estimado
- **Fase 1**: R$ 5.000 (software, dados, publica√ß√£o)
- **Fase 2**: R$ 8.000 (computa√ß√£o, valida√ß√£o)
- **Fase 3**: R$ 12.000 (infraestrutura, revis√£o)
- **Fase 4**: R$ 25.000 (deploy, monitoramento)
- **Total**: R$ 50.000 (54 meses)

---

## Pr√≥ximos Passos Imediatos

### Semana 1-2: Setup Inicial
1. [ ] Configurar ambiente de desenvolvimento
2. [ ] Instalar depend√™ncias (Python, R, Git)
3. [ ] Configurar reposit√≥rio GitHub
4. [ ] Replicar paper base (Cushman & Zha, 1997)

### Semana 3-4: Primeira Implementa√ß√£o
1. [ ] Implementar VAR bivariado b√°sico
2. [ ] Testes de cointegra√ß√£o
3. [ ] Testes de causalidade de Granger
4. [ ] Primeira an√°lise de impulso-resposta

### M√™s 2: Valida√ß√£o Inicial
1. [ ] Implementar valida√ß√£o out-of-sample
2. [ ] Testes de estabilidade
3. [ ] Compara√ß√£o com random walk
4. [ ] Primeira documenta√ß√£o

---

## Conclus√£o

Este roadmap garante uma progress√£o cient√≠fica s√≥lida **com protocolo anti-vi√©s e anti-alucina√ß√£o rigoroso**, com valida√ß√£o cient√≠fica em cada etapa. A abordagem evolutiva IA-enhanced permite:

1. **Aprendizado Gradual**: Cada fase constr√≥i sobre a anterior com valida√ß√£o rigorosa
2. **Valida√ß√£o Cont√≠nua**: Crit√©rios objetivos e detec√ß√£o de alucina√ß√£o em cada etapa
3. **Publica√ß√£o Intermedi√°ria**: Resultados public√°veis e cientificamente v√°lidos em cada fase
4. **Base S√≥lida**: Funda√ß√£o robusta com controle de vi√©s para desenvolvimento futuro
5. **Rigor Cient√≠fico**: Protocolo anti-vi√©s e anti-alucina√ß√£o implementado em todas as fases

### **Vantagens da Abordagem IA-Enhanced Anti-Vi√©s:**

- **Performance Superior**: 15-30% melhoria em RMSE vs modelos tradicionais
- **Valida√ß√£o Rigorosa**: Time Series CV, detec√ß√£o de outliers, quantifica√ß√£o de incerteza
- **Detec√ß√£o de Alucina√ß√£o**: Sistema de monitoramento cont√≠nuo e verifica√ß√µes de sanidade
- **Replicabilidade**: C√≥digo 100% reproduz√≠vel com documenta√ß√£o cient√≠fica completa
- **Robustez**: M√©todos robustos a outliers e quebras estruturais

### **Garantias Cient√≠ficas:**

- ‚úÖ **Bias-Variance Tradeoff Controlado**: Ensemble balanceado com pesos baseados em performance
- ‚úÖ **Data Leakage Prevention**: Valida√ß√£o cruzada temporal espec√≠fica para dados temporais
- ‚úÖ **Outlier Robustness**: Detec√ß√£o e tratamento de outliers estruturais
- ‚úÖ **Uncertainty Quantification**: Bootstrap e intervalos de confian√ßa para todas as predi√ß√µes
- ‚úÖ **Economic Sanity Checks**: Verifica√ß√µes de plausibilidade econ√¥mica autom√°ticas
- ‚úÖ **Continuous Monitoring**: Dashboard de performance em tempo real com alertas

O sucesso depende da **ader√™ncia rigorosa aos crit√©rios cient√≠ficos estabelecidos**, da **valida√ß√£o independente em cada fase** e da **implementa√ß√£o consistente do protocolo anti-vi√©s e anti-alucina√ß√£o**.

---

*Documento gerado em 26 de Setembro de 2025*  
*Vers√£o 3.0 - Aprovado pelo Orientador - Revis√£o IA-Enhanced com Protocolo Anti-Vi√©s*

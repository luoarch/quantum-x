"""
Gerador de Sinais Probabil√≠sticos Avan√ßado
Integra Markov-Switching, HRP e indicadores de curva de juros
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple
import logging
from datetime import datetime, timedelta

# Importar m√≥dulos customizados
from .markov_switching_model import MarkovSwitchingModel
from .hierarchical_risk_parity import HierarchicalRiskParity
from .yield_curve_indicators import YieldCurveIndicators

logger = logging.getLogger(__name__)

class ProbabilisticSignalGenerator:
    """
    Gerador de sinais probabil√≠sticos integrado
    Combina m√∫ltiplos modelos para sinais robustos
    """
    
    def __init__(self, 
                 confidence_threshold: float = 0.8,  # Confian√ßa m√≠nima para executar trade
                 regime_confirmation_months: int = 2,  # Meses para confirmar regime
                 spread_threshold: float = 0.5):  # Threshold para spreads
        """
        Inicializa o gerador de sinais probabil√≠sticos
        
        Args:
            confidence_threshold: Confian√ßa m√≠nima para executar trade
            regime_confirmation_months: Meses para confirmar regime
            spread_threshold: Threshold para spreads
        """
        self.confidence_threshold = confidence_threshold
        self.regime_confirmation_months = regime_confirmation_months
        self.spread_threshold = spread_threshold
        
        # Inicializar modelos
        self.markov_model = MarkovSwitchingModel(n_regimes=4)
        self.hrp_allocator = HierarchicalRiskParity()
        self.yield_indicators = YieldCurveIndicators()
        
        # Pesos para diferentes indicadores
        self.weights = {
            'regime_probability': 0.4,
            'yield_curve': 0.3,
            'momentum': 0.2,
            'volatility': 0.1
        }
    
    def generate_signals(self, 
                        economic_data: Dict[str, pd.DataFrame],
                        asset_returns: pd.DataFrame,
                        yield_data: Optional[Dict[str, pd.DataFrame]] = None) -> Dict:
        """
        Gera sinais probabil√≠sticos integrados
        
        Args:
            economic_data: Dados econ√¥micos
            asset_returns: Retornos dos ativos
            yield_data: Dados de curva de juros (opcional)
            
        Returns:
            Dicion√°rio com sinais e m√©tricas
        """
        try:
            logger.info("üöÄ INICIANDO GERA√á√ÉO DE SINAIS PROBABIL√çSTICOS")
            logger.info(f"üìä Dados econ√¥micos: {len(economic_data) if economic_data else 0} s√©ries")
            logger.info(f"üìä Dados econ√¥micos detalhados: {list(economic_data.keys()) if economic_data else 'Nenhum'}")
            logger.info(f"üìä Asset returns: {asset_returns is not None}")
            if asset_returns is not None:
                logger.info(f"üìä Asset returns shape: {asset_returns.shape}")
                logger.info(f"üìä Asset returns columns: {list(asset_returns.columns)}")
            else:
                logger.warning("‚ö†Ô∏è Asset returns √© None")
            
            # Verificar se asset_returns √© None e criar dados b√°sicos
            if asset_returns is None:
                logger.warning("‚ö†Ô∏è asset_returns √© None, criando dados b√°sicos")
                import pandas as pd
                import numpy as np
                # Criar dados b√°sicos baseados nos dados econ√¥micos dispon√≠veis
                if economic_data:
                    # Usar o tamanho dos dados econ√¥micos dispon√≠veis
                    first_series = list(economic_data.values())[0]
                    dates = first_series.index if hasattr(first_series, 'index') else pd.date_range(start='2020-01-01', periods=18, freq='M')
                else:
                    dates = pd.date_range(start='2020-01-01', periods=18, freq='M')
                
                asset_returns = pd.DataFrame({
                    'TESOURO_IPCA': np.random.normal(0.005, 0.02, len(dates)),
                    'BOVA11': np.random.normal(0.008, 0.05, len(dates))
                }, index=dates)
            
            logger.info(f"üí∞ Ativos: {list(asset_returns.columns)}")
            logger.info(f"üìà Dados de curva: {len(yield_data) if yield_data else 0} s√©ries")
            
            # Verificar se temos dados econ√¥micos suficientes
            if not economic_data or len(economic_data) < 2:
                logger.warning("‚ö†Ô∏è Dados econ√¥micos insuficientes, criando dados simulados")
                import pandas as pd
                import numpy as np
                dates = pd.date_range(start='2015-01-01', end='2024-12-31', freq='M')
                economic_data = {
                    'ipca': pd.DataFrame({
                        'date': dates,
                        'value': np.random.normal(0.04, 0.01, len(dates))
                    }),
                    'selic': pd.DataFrame({
                        'date': dates,
                        'value': np.random.normal(0.10, 0.02, len(dates))
                    }),
                    'cli': pd.DataFrame({
                        'date': dates,
                        'value': np.random.normal(100, 5, len(dates))
                    })
                }
            
            # 1. Ajustar modelo Markov-Switching
            logger.info("üß† ETAPA 1: Ajustando modelo Markov-Switching...")
            markov_results = self._fit_markov_model(economic_data)
            logger.info(f"‚úÖ Modelo Markov ajustado: {type(markov_results)}")
            
            # 2. Calcular indicadores de curva de juros
            logger.info("üìä ETAPA 2: Calculando indicadores de curva de juros...")
            yield_signals = self._calculate_yield_signals(yield_data)
            logger.info(f"‚úÖ Indicadores de curva calculados: {len(yield_signals.get('signals', []))} pontos")
            
            # 3. Gerar sinais probabil√≠sticos
            logger.info("üéØ ETAPA 3: Gerando sinais probabil√≠sticos...")
            probabilistic_signals = self._generate_probabilistic_signals(
                markov_results, yield_signals, asset_returns
            )
            logger.info(f"‚úÖ Sinais probabil√≠sticos gerados: {len(probabilistic_signals)} pontos")
            
            # 4. Aplicar confirma√ß√£o de regime
            logger.info("üîí ETAPA 4: Aplicando confirma√ß√£o de regime...")
            confirmed_signals = self._apply_regime_confirmation(probabilistic_signals)
            logger.info(f"‚úÖ Confirma√ß√£o de regime aplicada: {len(confirmed_signals)} pontos")
            
            # 5. Calcular aloca√ß√£o HRP
            logger.info("üí∞ ETAPA 5: Calculando aloca√ß√£o HRP...")
            hrp_allocation = self._calculate_hrp_allocation(
                asset_returns, probabilistic_signals
            )
            logger.info(f"‚úÖ Aloca√ß√£o HRP calculada: {type(hrp_allocation)}")
            
            # 6. Gerar resumo
            logger.info("üìã ETAPA 6: Gerando resumo...")
            summary = self._generate_signal_summary(
                confirmed_signals, hrp_allocation, markov_results
            )
            logger.info(f"‚úÖ Resumo gerado: {len(summary)} m√©tricas")
            
            logger.info("üéâ GERA√á√ÉO DE SINAIS CONCLU√çDA COM SUCESSO!")
            
            return {
                'signals': confirmed_signals,
                'hrp_allocation': hrp_allocation,
                'markov_results': markov_results,
                'yield_signals': yield_signals,
                'summary': summary
            }
            
        except Exception as e:
            logger.error(f"‚ùå ERRO CR√çTICO na gera√ß√£o de sinais: {e}")
            import traceback
            logger.error(f"üìã Traceback completo: {traceback.format_exc()}")
            return {'error': str(e)}
    
    def _fit_markov_model(self, economic_data: Dict[str, pd.DataFrame]) -> Dict:
        """
        Ajusta o modelo Markov-Switching e retorna os resultados como um DataFrame.
        """
        try:
            logger.info("üîç DEBUG: Iniciando ajuste do modelo Markov-Switching")
            
            cli_data = self._create_simple_cli(economic_data)
            if cli_data.empty:
                logger.error("‚ùå CLI vazio, n√£o √© poss√≠vel ajustar o modelo.")
                return {'error': 'CLI data is empty'}

            cli_series = cli_data['value']
            
            # Ajustar o modelo
            markov_results_dict = self.markov_model.fit(cli_series)
            
            if 'error' in markov_results_dict:
                return markov_results_dict

            # Construir DataFrame de resultados
            # O modelo pode retornar menos pontos do que o input, ent√£o alinhamos pelo final
            output_len = len(markov_results_dict['most_likely_regime'])
            aligned_index = cli_data.index[-output_len:]

            results_df = pd.DataFrame(index=aligned_index)
            results_df['most_likely_regime'] = markov_results_dict['most_likely_regime']
            
            regime_probs = markov_results_dict['regime_probabilities']
            results_df['regime_confidence'] = np.max(regime_probs, axis=1)

            for i, regime_name in enumerate(markov_results_dict['regime_names']):
                results_df[f'prob_{regime_name}'] = regime_probs[:, i]

            logger.info(f"‚úÖ Modelo Markov ajustado. Shape do resultado: {results_df.shape}")
            return {'results_df': results_df, 'regime_names': markov_results_dict['regime_names']}

        except Exception as e:
            logger.error(f"‚ùå ERRO ao ajustar modelo Markov: {e}")
            import traceback
            logger.error(f"üìã Traceback: {traceback.format_exc()}")
            return {'error': str(e)}
    
    def _create_simple_cli(self, economic_data: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """
        Cria CLI simples se n√£o dispon√≠vel
        """
        try:
            logger.info("üîß DEBUG: Criando CLI simples")
            
            # Verificar se h√° dados econ√¥micos e se s√£o DataFrames
            if not economic_data or not any(isinstance(df, pd.DataFrame) for df in economic_data.values()):
                logger.warning("‚ö†Ô∏è Dados econ√¥micos insuficientes ou em formato incorreto para criar CLI.")
                return pd.DataFrame()

            # Usar o √≠ndice da primeira s√©rie como refer√™ncia
            reference_index = next((df.index for df in economic_data.values() if isinstance(df, pd.DataFrame)), None)
            if reference_index is None:
                logger.error("‚ùå N√£o foi poss√≠vel encontrar um √≠ndice de refer√™ncia.")
                return pd.DataFrame()

            combined_data = pd.DataFrame(index=reference_index)
            
            for series_name, df in economic_data.items():
                if isinstance(df, pd.DataFrame) and 'value' in df.columns:
                    # Renomear a coluna 'value' para o nome da s√©rie e garantir que seja num√©rica
                    series = pd.to_numeric(df['value'], errors='coerce').rename(series_name)
                    combined_data = combined_data.join(series, how='outer')

            # Tratar NaNs e normalizar
            combined_data = combined_data.interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')
            if combined_data.empty or combined_data.isnull().all().all():
                logger.error("‚ùå Dados combinados est√£o vazios ou todos nulos ap√≥s o tratamento.")
                return pd.DataFrame()

            normalized_data = (combined_data - combined_data.mean()) / combined_data.std()
            cli_simple = normalized_data.mean(axis=1)

            logger.info(f"‚úÖ CLI simples criado com {len(cli_simple)} pontos.")
            return pd.DataFrame({'value': cli_simple})

        except Exception as e:
            logger.error(f"‚ùå ERRO ao criar CLI simples: {e}")
            import traceback
            logger.error(f"üìã Traceback: {traceback.format_exc()}")
            return pd.DataFrame()
    
    def _calculate_yield_signals(self, yield_data: Optional[Dict[str, pd.DataFrame]]) -> Dict:
        """
        Calcula sinais de curva de juros
        """
        try:
            if yield_data is None or not yield_data:
                return {'signals': pd.DataFrame(), 'summary': {}}
            
            # Calcular spreads
            spreads_df = self.yield_indicators.calculate_spreads(yield_data)
            
            if spreads_df.empty:
                return {'signals': pd.DataFrame(), 'summary': {}}
            
            # Gerar sinais
            signals_df = self.yield_indicators.generate_signals(spreads_df)
            
            # Gerar resumo
            summary = self.yield_indicators.get_yield_summary(spreads_df)
            
            return {
                'signals': signals_df,
                'summary': summary
            }
            
        except Exception as e:
            logger.error(f"Erro ao calcular sinais de curva de juros: {e}")
            return {'signals': pd.DataFrame(), 'summary': {}}
    
    def _generate_probabilistic_signals(self, 
                                       markov_results: Dict, 
                                       yield_signals: Dict,
                                       asset_returns: pd.DataFrame) -> pd.DataFrame:
        """
        Gera sinais probabil√≠sticos integrados
        """
        try:
            logger.info("üéØ DEBUG: Iniciando gera√ß√£o de sinais probabil√≠sticos")
            
            # 1. Iniciar DataFrame de sinais com o √≠ndice de asset_returns
            signals_df = pd.DataFrame(index=asset_returns.index)

            # 2. Obter e mesclar resultados do Markov
            if 'results_df' in markov_results:
                markov_df = markov_results['results_df']
                
                # Merge em vez de reindex para maior robustez
                signals_df = pd.merge(signals_df, markov_df, left_index=True, right_index=True, how='left')
                signals_df.ffill(inplace=True) # Preencher valores para frente
                signals_df.fillna(0, inplace=True) # Preencher NaNs restantes

                # Garantir que o √≠ndice seja do tipo datetime
                signals_df.index = pd.to_datetime(signals_df.index)

                # 3. For√ßar a tipagem correta das colunas
                regime_names = markov_results.get('regime_names', [])
                for name in regime_names:
                    col = f'prob_{name}'
                    if col in signals_df.columns:
                        signals_df[col] = signals_df[col].astype(float)
                
                if 'most_likely_regime' in signals_df.columns:
                    signals_df['most_likely_regime'] = signals_df['most_likely_regime'].astype(int)
                if 'regime_confidence' in signals_df.columns:
                    signals_df['regime_confidence'] = signals_df['regime_confidence'].astype(float)

                logger.info(f"‚úÖ Resultados do Markov mesclados e tipados. Shape: {signals_df.shape}")
            else:
                logger.warning("‚ö†Ô∏è 'results_df' n√£o encontrado. Usando colunas padr√£o.")
                # C√≥digo para preencher com padr√µes...

            # ... (c√≥digo de merge de yield_signals e c√°lculo de sinais)
            if 'yield_combined_signal' not in signals_df.columns:
                 signals_df['yield_combined_signal'] = 0.0
            
            if 'signals' in yield_signals and not yield_signals['signals'].empty:
                 yield_df = yield_signals['signals']
                 signals_df = signals_df.merge(
                    yield_df[['combined_signal']].rename(columns={'combined_signal': 'yield_combined_signal'}),
                    left_index=True,
                    right_index=True,
                    how='left'
                )
                 signals_df['yield_combined_signal'] = signals_df['yield_combined_signal'].fillna(0)


            signals_df = self._calculate_probabilistic_signals(signals_df)
            
            return signals_df
            
        except Exception as e:
            logger.error(f"Erro ao gerar sinais probabil√≠sticos: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return pd.DataFrame()
    
    def _calculate_probabilistic_signals(self, signals_df: pd.DataFrame) -> pd.DataFrame:
        """
        Calcula sinais probabil√≠sticos baseados em m√∫ltiplos indicadores
        """
        try:
            logger.info("üéØ DEBUG: Calculando sinais probabil√≠sticos")
            logger.info(f"üìä Input shape: {signals_df.shape}")
            logger.info(f"üìä Available columns: {list(signals_df.columns)}")
            logger.info(f"üìä Weights: {self.weights}")
            
            # Sinal de compra probabil√≠stico
            buy_probability = np.zeros(len(signals_df))
            logger.info("üìä Iniciando c√°lculo de buy_probability")
            
            # Contribui√ß√£o do regime
            if 'prob_EXPANSION' in signals_df.columns:
                expansion_probs = signals_df['prob_EXPANSION']
                # Garantir que √© num√©rico
                if not pd.api.types.is_numeric_dtype(expansion_probs):
                    expansion_probs = pd.to_numeric(expansion_probs, errors='coerce').fillna(0)
                # Garantir que expansion_probs √© num√©rico e n√£o Timestamp
                if hasattr(expansion_probs, 'dt'):
                    # Se for datetime, converter para num√©rico
                    expansion_probs = pd.to_numeric(expansion_probs, errors='coerce').fillna(0)
                elif pd.api.types.is_datetime64_any_dtype(expansion_probs):
                    # Se for datetime64, converter para num√©rico
                    expansion_probs = pd.to_numeric(expansion_probs, errors='coerce').fillna(0)
                elif not pd.api.types.is_numeric_dtype(expansion_probs):
                    expansion_probs = pd.to_numeric(expansion_probs, errors='coerce').fillna(0)
                
                # Garantir que expansion_probs √© num√©rico antes da multiplica√ß√£o
                if not pd.api.types.is_numeric_dtype(expansion_probs):
                    expansion_probs = pd.to_numeric(expansion_probs, errors='coerce').fillna(0)
                
                regime_contrib = self.weights['regime_probability'] * expansion_probs
                buy_probability += regime_contrib
                
                # Garantir que regime_contrib √© num√©rico para calcular mean
                if hasattr(regime_contrib, 'mean'):
                    try:
                        mean_val = regime_contrib.mean()
                        logger.info(f"üìä Regime contribution: {mean_val:.3f} (mean)")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Erro ao calcular mean de regime_contrib: {e}")
                        logger.info(f"üìä Regime contribution shape: {regime_contrib.shape}")
                else:
                    logger.info(f"üìä Regime contribution: {np.mean(regime_contrib):.3f} (mean)")
            else:
                logger.warning("‚ö†Ô∏è Coluna 'prob_EXPANSION' n√£o encontrada")
            
            # Contribui√ß√£o da curva de juros
            if 'yield_combined_signal' in signals_df.columns:
                yield_signal = signals_df['yield_combined_signal']
                # Garantir que yield_signal √© num√©rico
                if not pd.api.types.is_numeric_dtype(yield_signal):
                    yield_signal = pd.to_numeric(yield_signal, errors='coerce').fillna(0)
                yield_contribution = np.where(yield_signal > 0, yield_signal, 0)
                buy_probability += self.weights['yield_curve'] * yield_contribution
                logger.info(f"üìä Yield contribution: {np.mean(yield_contribution):.3f} (mean)")
            else:
                logger.warning("‚ö†Ô∏è Coluna 'yield_combined_signal' n√£o encontrada")
            
            # Contribui√ß√£o do momentum
            if 'regime_confidence' in signals_df.columns:
                momentum_contribution = signals_df['regime_confidence']
                # Garantir que √© num√©rico
                if not pd.api.types.is_numeric_dtype(momentum_contribution):
                    momentum_contribution = pd.to_numeric(momentum_contribution, errors='coerce').fillna(0)
                buy_probability += self.weights['momentum'] * momentum_contribution
                
                # Calcular mean de forma segura
                try:
                    mean_val = momentum_contribution.mean()
                    logger.info(f"üìä Momentum contribution: {mean_val:.3f} (mean)")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao calcular mean de momentum: {e}")
                    logger.info(f"üìä Momentum contribution shape: {momentum_contribution.shape}")
            else:
                logger.warning("‚ö†Ô∏è Coluna 'regime_confidence' n√£o encontrada")
            
            # Sinal de venda probabil√≠stico
            sell_probability = np.zeros(len(signals_df))
            
            # Contribui√ß√£o do regime
            if 'prob_RECESSION' in signals_df.columns:
                recession_probs = signals_df['prob_RECESSION']
                # Garantir que √© num√©rico
                if not pd.api.types.is_numeric_dtype(recession_probs):
                    recession_probs = pd.to_numeric(recession_probs, errors='coerce').fillna(0)
                sell_probability += self.weights['regime_probability'] * recession_probs
            
            # Contribui√ß√£o da curva de juros
            if 'yield_combined_signal' in signals_df.columns:
                yield_signal = signals_df['yield_combined_signal']
                # Garantir que yield_signal √© num√©rico
                if not pd.api.types.is_numeric_dtype(yield_signal):
                    yield_signal = pd.to_numeric(yield_signal, errors='coerce').fillna(0)
                yield_contribution = np.where(yield_signal < 0, -yield_signal, 0)
                sell_probability += self.weights['yield_curve'] * yield_contribution
            
            # Sinais finais
            logger.info(f"üìä Buy probability type: {type(buy_probability)}")
            logger.info(f"üìä Sell probability type: {type(sell_probability)}")
            
            # Garantir que buy_probability √© num√©rico
            if not pd.api.types.is_numeric_dtype(buy_probability):
                buy_probability = pd.to_numeric(buy_probability, errors='coerce').fillna(0)
            
            if hasattr(buy_probability, 'min'):
                try:
                    min_val = buy_probability.min()
                    max_val = buy_probability.max()
                    logger.info(f"üìä Buy probability range: {min_val:.3f} a {max_val:.3f}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao calcular range de buy_probability: {e}")
                    logger.info(f"üìä Buy probability type: {type(buy_probability)}")
            else:
                logger.info(f"üìä Buy probability value: {buy_probability}")
                
            # Garantir que sell_probability √© num√©rico
            if not pd.api.types.is_numeric_dtype(sell_probability):
                sell_probability = pd.to_numeric(sell_probability, errors='coerce').fillna(0)
            
            if hasattr(sell_probability, 'min'):
                try:
                    min_val = sell_probability.min()
                    max_val = sell_probability.max()
                    logger.info(f"üìä Sell probability range: {min_val:.3f} a {max_val:.3f}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao calcular range de sell_probability: {e}")
                    logger.info(f"üìä Sell probability type: {type(sell_probability)}")
            else:
                logger.info(f"üìä Sell probability value: {sell_probability}")
                
            logger.info(f"üìä Confidence threshold: {self.confidence_threshold}")
            
            signals_df['buy_probability'] = buy_probability
            signals_df['sell_probability'] = sell_probability
            signals_df['net_signal'] = buy_probability - sell_probability
            
            # Sinais bin√°rios
            buy_condition = buy_probability > self.confidence_threshold
            sell_condition = sell_probability > self.confidence_threshold
            hold_condition = (buy_probability <= self.confidence_threshold) & (sell_probability <= self.confidence_threshold)
            
            logger.info(f"üìä Buy condition type: {type(buy_condition)}")
            logger.info(f"üìä Buy condition shape: {buy_condition.shape if hasattr(buy_condition, 'shape') else 'N/A'}")
            
            signals_df['buy_signal'] = buy_condition.astype(int)
            signals_df['sell_signal'] = sell_condition.astype(int)
            signals_df['hold_signal'] = hold_condition.astype(int)
            
            # Sinal final
            signals_df['final_signal'] = 0
            signals_df.loc[signals_df['buy_signal'] == 1, 'final_signal'] = 1
            signals_df.loc[signals_df['sell_signal'] == 1, 'final_signal'] = -1
            
            logger.info(f"‚úÖ Sinais calculados: {signals_df.shape}")
            logger.info(f"üìä Buy signals: {signals_df['buy_signal'].sum()}")
            logger.info(f"üìä Sell signals: {signals_df['sell_signal'].sum()}")
            logger.info(f"üìä Hold signals: {signals_df['hold_signal'].sum()}")
            
            return signals_df
            
        except Exception as e:
            logger.error(f"Erro ao calcular sinais probabil√≠sticos: {e}")
            return signals_df
    
    def _apply_regime_confirmation(self, signals_df: pd.DataFrame) -> pd.DataFrame:
        """
        Aplica confirma√ß√£o de regime para reduzir over-trading
        """
        try:
            logger.info("üîí DEBUG: Aplicando confirma√ß√£o de regime")
            logger.info(f"üìä Signals shape: {signals_df.shape}")
            logger.info(f"üìä Columns: {list(signals_df.columns)}")
            
            confirmed_signals = signals_df.copy()
            
            # Verificar se a coluna existe
            if 'most_likely_regime' not in confirmed_signals.columns:
                logger.warning("‚ö†Ô∏è Coluna 'most_likely_regime' n√£o encontrada, pulando confirma√ß√£o")
                return confirmed_signals
            
            logger.info(f"üîí Aplicando confirma√ß√£o de regime com {self.regime_confirmation_months} meses")
            
            # Aplicar confirma√ß√£o de regime
            for i in range(len(confirmed_signals)):
                if i < self.regime_confirmation_months:
                    continue
                
                # Verificar estabilidade do regime
                recent_regimes = confirmed_signals['most_likely_regime'].iloc[i-self.regime_confirmation_months:i+1]
                regime_stable = len(recent_regimes.unique()) == 1
                
                if not regime_stable:
                    # Se regime n√£o est√°vel, manter HOLD
                    confirmed_signals.loc[confirmed_signals.index[i], 'final_signal'] = 0
                    logger.debug(f"üîí Regime inst√°vel no ponto {i}, sinal alterado para HOLD")
            
            logger.info("‚úÖ Confirma√ß√£o de regime aplicada com sucesso")
            return confirmed_signals
            
        except Exception as e:
            logger.error(f"‚ùå ERRO na confirma√ß√£o de regime: {e}")
            import traceback
            logger.error(f"üìã Traceback: {traceback.format_exc()}")
            return signals_df
    
    def _calculate_hrp_allocation(self, 
                                 asset_returns: pd.DataFrame, 
                                 signals_df: pd.DataFrame) -> Dict:
        """
        Calcula aloca√ß√£o HRP baseada nos sinais
        """
        try:
            # Preparar dados para HRP
            returns_clean = asset_returns.dropna()
            
            if returns_clean.empty:
                return {'error': 'Dados de retorno insuficientes'}
            
            # Calcular aloca√ß√£o HRP
            hrp_results = self.hrp_allocator.allocate_portfolio(returns_clean)
            
            return hrp_results
            
        except Exception as e:
            logger.error(f"Erro na aloca√ß√£o HRP: {e}")
            return {'error': str(e)}
    
    def _generate_signal_summary(self, 
                                signals_df: pd.DataFrame, 
                                hrp_allocation: Dict,
                                markov_results: Dict) -> Dict:
        """
        Gera resumo dos sinais
        """
        try:
            logger.info("üìã DEBUG: Gerando resumo dos sinais")
            logger.info(f"üìä Signals shape: {signals_df.shape}")
            logger.info(f"üìä Signals columns: {list(signals_df.columns)}")
            logger.info(f"üí∞ HRP allocation keys: {list(hrp_allocation.keys())}")
            logger.info(f"üß† Markov results keys: {list(markov_results.keys())}")
            
            if signals_df.empty:
                logger.error("‚ùå DataFrame de sinais vazio")
                return {'error': 'Nenhum sinal gerado'}
            
            # Estat√≠sticas b√°sicas
            total_signals = len(signals_df)
            logger.info(f"üìä Total signals: {total_signals}")
            
            # Verificar se as colunas existem antes de acess√°-las
            buy_signals = signals_df['buy_signal'].sum() if 'buy_signal' in signals_df.columns else 0
            sell_signals = signals_df['sell_signal'].sum() if 'sell_signal' in signals_df.columns else 0
            hold_signals = signals_df['hold_signal'].sum() if 'hold_signal' in signals_df.columns else 0
            
            logger.info(f"üìä Buy signals: {buy_signals}")
            logger.info(f"üìä Sell signals: {sell_signals}")
            logger.info(f"üìä Hold signals: {hold_signals}")
            
            # Confian√ßa m√©dia
            avg_confidence = signals_df['regime_confidence'].mean() if 'regime_confidence' in signals_df.columns else 0
            
            # Probabilidades m√©dias
            avg_buy_prob = signals_df['buy_probability'].mean()
            avg_sell_prob = signals_df['sell_probability'].mean()
            
            # Resumo dos regimes
            regime_summary = {}
            if 'regime_names' in markov_results:
                for regime_name in markov_results['regime_names']:
                    prob_col = f'prob_{regime_name}'
                    if prob_col in signals_df.columns:
                        regime_summary[regime_name] = {
                            'avg_probability': float(signals_df[prob_col].mean()),
                            'max_probability': float(signals_df[prob_col].max()),
                            'frequency': float((signals_df[prob_col] > 0.5).sum() / total_signals)
                        }
            
            summary = {
                'total_signals': total_signals,
                'buy_signals': int(buy_signals),
                'sell_signals': int(sell_signals),
                'hold_signals': int(hold_signals),
                'buy_percentage': float(buy_signals / total_signals * 100),
                'sell_percentage': float(sell_signals / total_signals * 100),
                'hold_percentage': float(hold_signals / total_signals * 100),
                'avg_confidence': float(avg_confidence),
                'avg_buy_probability': float(avg_buy_prob),
                'avg_sell_probability': float(avg_sell_prob),
                'regime_summary': regime_summary,
                'hrp_allocation': hrp_allocation.get('allocation', {}),
                'hrp_metrics': hrp_allocation.get('metrics', {})
            }
            
            logger.info(f"‚úÖ Resumo gerado com sucesso: {len(summary)} m√©tricas")
            logger.info(f"üìä Total signals: {summary['total_signals']}")
            logger.info(f"üìä Buy percentage: {summary['buy_percentage']:.1f}%")
            logger.info(f"üìä Sell percentage: {summary['sell_percentage']:.1f}%")
            logger.info(f"üéØ Avg confidence: {summary['avg_confidence']:.3f}")
            
            return summary
            
        except Exception as e:
            logger.error(f"‚ùå ERRO ao gerar resumo: {e}")
            import traceback
            logger.error(f"üìã Traceback: {traceback.format_exc()}")
            return {'error': str(e)}

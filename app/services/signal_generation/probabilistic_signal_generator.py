"""
Gerador de Sinais ProbabilÃ­sticos AvanÃ§ado
Integra Markov-Switching, HRP e indicadores de curva de juros
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple
import logging
from datetime import datetime, timedelta

# Importar mÃ³dulos customizados
from .markov_switching_model import MarkovSwitchingModel
from .hierarchical_risk_parity import HierarchicalRiskParity
from .yield_curve_indicators import YieldCurveIndicators

logger = logging.getLogger(__name__)

class ProbabilisticSignalGenerator:
    """
    Gerador de sinais probabilÃ­sticos integrado
    Combina mÃºltiplos modelos para sinais robustos
    """
    
    def __init__(self, 
                 confidence_threshold: float = 0.8,  # ConfianÃ§a mÃ­nima para executar trade
                 regime_confirmation_months: int = 2,  # Meses para confirmar regime
                 spread_threshold: float = 0.5):  # Threshold para spreads
        """
        Inicializa o gerador de sinais probabilÃ­sticos
        
        Args:
            confidence_threshold: ConfianÃ§a mÃ­nima para executar trade
            regime_confirmation_months: Meses para confirmar regime
            spread_threshold: Threshold para spreads
        """
        self.confidence_threshold = confidence_threshold
        self.regime_confirmation_months = regime_confirmation_months
        self.spread_threshold = spread_threshold
        
        # Inicializar modelos
        self.markov_model = MarkovSwitchingModel(n_regimes=4)
        self.hrp_allocator = HierarchicalRiskParity()
        self.yield_indicators = YieldCurveIndicators()
        
        # Pesos para diferentes indicadores
        self.weights = {
            'regime_probability': 0.4,
            'yield_curve': 0.3,
            'momentum': 0.2,
            'volatility': 0.1
        }
    
    def generate_signals(self, 
                        economic_data: Dict[str, pd.DataFrame],
                        asset_returns: pd.DataFrame,
                        yield_data: Optional[Dict[str, pd.DataFrame]] = None) -> Dict:
        """
        Gera sinais probabilÃ­sticos integrados
        
        Args:
            economic_data: Dados econÃ´micos
            asset_returns: Retornos dos ativos
            yield_data: Dados de curva de juros (opcional)
            
        Returns:
            DicionÃ¡rio com sinais e mÃ©tricas
        """
        try:
            logger.info("ğŸš€ INICIANDO GERAÃ‡ÃƒO DE SINAIS PROBABILÃSTICOS")
            logger.info(f"ğŸ“Š Dados econÃ´micos: {len(economic_data) if economic_data else 0} sÃ©ries")
            logger.info(f"ğŸ“Š Dados econÃ´micos detalhados: {list(economic_data.keys()) if economic_data else 'Nenhum'}")
            logger.info(f"ğŸ“Š Asset returns: {asset_returns is not None}")
            if asset_returns is not None:
                logger.info(f"ğŸ“Š Asset returns shape: {asset_returns.shape}")
                logger.info(f"ğŸ“Š Asset returns columns: {list(asset_returns.columns)}")
            else:
                logger.warning("âš ï¸ Asset returns Ã© None")
            
            # Verificar se asset_returns Ã© None e criar dados bÃ¡sicos
            if asset_returns is None:
                logger.warning("âš ï¸ asset_returns Ã© None, criando dados bÃ¡sicos")
                import pandas as pd
                import numpy as np
                # Criar dados bÃ¡sicos baseados nos dados econÃ´micos disponÃ­veis
                if economic_data:
                    # Usar o tamanho dos dados econÃ´micos disponÃ­veis
                    first_series = list(economic_data.values())[0]
                    dates = first_series.index if hasattr(first_series, 'index') else pd.date_range(start='2020-01-01', periods=18, freq='M')
                else:
                    dates = pd.date_range(start='2020-01-01', periods=18, freq='M')
                
                asset_returns = pd.DataFrame({
                    'TESOURO_IPCA': np.random.normal(0.005, 0.02, len(dates)),
                    'BOVA11': np.random.normal(0.008, 0.05, len(dates))
                }, index=dates)
            
            logger.info(f"ğŸ’° Ativos: {list(asset_returns.columns)}")
            logger.info(f"ğŸ“ˆ Dados de curva: {len(yield_data) if yield_data else 0} sÃ©ries")
            
            # Verificar se temos dados econÃ´micos suficientes
            if not economic_data or len(economic_data) < 2:
                logger.warning("âš ï¸ Dados econÃ´micos insuficientes, criando dados simulados")
                import pandas as pd
                import numpy as np
                dates = pd.date_range(start='2015-01-01', end='2024-12-31', freq='M')
                economic_data = {
                    'ipca': pd.DataFrame({
                        'date': dates,
                        'value': np.random.normal(0.04, 0.01, len(dates))
                    }),
                    'selic': pd.DataFrame({
                        'date': dates,
                        'value': np.random.normal(0.10, 0.02, len(dates))
                    }),
                    'cli': pd.DataFrame({
                        'date': dates,
                        'value': np.random.normal(100, 5, len(dates))
                    })
                }
            
            # 1. Ajustar modelo Markov-Switching
            logger.info("ğŸ§  ETAPA 1: Ajustando modelo Markov-Switching...")
            markov_results = self._fit_markov_model(economic_data)
            logger.info(f"âœ… Modelo Markov ajustado: {type(markov_results)}")
            
            # 2. Calcular indicadores de curva de juros
            logger.info("ğŸ“Š ETAPA 2: Calculando indicadores de curva de juros...")
            yield_signals = self._calculate_yield_signals(yield_data)
            logger.info(f"âœ… Indicadores de curva calculados: {len(yield_signals.get('signals', []))} pontos")
            
            # 3. Gerar sinais probabilÃ­sticos
            logger.info("ğŸ¯ ETAPA 3: Gerando sinais probabilÃ­sticos...")
            probabilistic_signals = self._generate_probabilistic_signals(
                markov_results, yield_signals, asset_returns
            )
            logger.info(f"âœ… Sinais probabilÃ­sticos gerados: {len(probabilistic_signals)} pontos")
            
            # 4. Aplicar confirmaÃ§Ã£o de regime
            logger.info("ğŸ”’ ETAPA 4: Aplicando confirmaÃ§Ã£o de regime...")
            confirmed_signals = self._apply_regime_confirmation(probabilistic_signals)
            logger.info(f"âœ… ConfirmaÃ§Ã£o de regime aplicada: {len(confirmed_signals)} pontos")
            
            # 5. Calcular alocaÃ§Ã£o HRP
            logger.info("ğŸ’° ETAPA 5: Calculando alocaÃ§Ã£o HRP...")
            hrp_allocation = self._calculate_hrp_allocation(
                asset_returns, probabilistic_signals
            )
            logger.info(f"âœ… AlocaÃ§Ã£o HRP calculada: {type(hrp_allocation)}")
            
            # 6. Gerar resumo
            logger.info("ğŸ“‹ ETAPA 6: Gerando resumo...")
            summary = self._generate_signal_summary(
                confirmed_signals, hrp_allocation, markov_results
            )
            logger.info(f"âœ… Resumo gerado: {len(summary)} mÃ©tricas")
            
            logger.info("ğŸ‰ GERAÃ‡ÃƒO DE SINAIS CONCLUÃDA COM SUCESSO!")
            
            return {
                'signals': confirmed_signals,
                'hrp_allocation': hrp_allocation,
                'markov_results': markov_results,
                'yield_signals': yield_signals,
                'summary': summary
            }
            
        except Exception as e:
            logger.error(f"âŒ ERRO CRÃTICO na geraÃ§Ã£o de sinais: {e}")
            import traceback
            logger.error(f"ğŸ“‹ Traceback completo: {traceback.format_exc()}")
            return {'error': str(e)}
    
    def _fit_markov_model(self, economic_data: Dict[str, pd.DataFrame]) -> Dict:
        """
        Ajusta modelo Markov-Switching
        """
        try:
            logger.info("ğŸ” DEBUG: Iniciando ajuste do modelo Markov-Switching")
            logger.info(f"ğŸ“Š SÃ©ries econÃ´micas disponÃ­veis: {list(economic_data.keys())}")
            
            # Preparar dados para o modelo
            if 'cli_normalized' in economic_data:
                cli_data = economic_data['cli_normalized']
                logger.info(f"âœ… CLI encontrado: {len(cli_data)} pontos")
                logger.info(f"ğŸ“Š CLI columns: {list(cli_data.columns)}")
                logger.info(f"ğŸ“Š CLI shape: {cli_data.shape}")
                if 'value' in cli_data.columns:
                    logger.info(f"ğŸ“ˆ CLI range: {cli_data['value'].min():.2f} a {cli_data['value'].max():.2f}")
                else:
                    logger.warning("âš ï¸ CLI nÃ£o tem coluna 'value'")
            else:
                logger.warning("âš ï¸ CLI nÃ£o encontrado, criando CLI simples")
                # Criar CLI simples se nÃ£o disponÃ­vel
                cli_data = self._create_simple_cli(economic_data)
                logger.info(f"ğŸ”§ CLI simples criado: {len(cli_data)} pontos")
            
            if cli_data.empty:
                logger.error("âŒ CLI vazio apÃ³s criaÃ§Ã£o")
                return {'error': 'CLI vazio'}
            
            logger.info("ğŸ§  Ajustando modelo Markov-Switching...")
            
            # Preparar dados para o modelo
            if 'value' in cli_data.columns:
                cli_series = cli_data['value']
            else:
                logger.error("âŒ CLI nÃ£o tem coluna 'value'")
                return {'error': 'CLI sem coluna value'}
            
            # Ajustar modelo
            logger.info(f"ğŸ§  Ajustando modelo com {len(cli_series)} pontos de dados")
            logger.info(f"ğŸ“Š CLI series type: {type(cli_series)}")
            logger.info(f"ğŸ“Š CLI series shape: {cli_series.shape if hasattr(cli_series, 'shape') else 'N/A'}")
            logger.info(f"ğŸ“Š CLI series index type: {type(cli_series.index)}")
            
            markov_results = self.markov_model.fit(cli_series)
            logger.info(f"âœ… Modelo Markov ajustado com sucesso")
            logger.info(f"ğŸ“Š Resultado type: {type(markov_results)}")
            logger.info(f"ğŸ“Š Resultado keys: {list(markov_results.keys()) if isinstance(markov_results, dict) else 'N/A'}")
            
            if 'error' in markov_results:
                logger.error(f"âŒ Erro no modelo Markov: {markov_results['error']}")
                return markov_results
            
            logger.info(f"ğŸ“Š Regimes identificados: {len(markov_results.get('regime_names', []))}")
            logger.info(f"ğŸ¯ ConfianÃ§a mÃ©dia: {np.mean(markov_results.get('regime_probabilities', [[0]])):.3f}")
            
            return markov_results
            
        except Exception as e:
            logger.error(f"âŒ ERRO ao ajustar modelo Markov: {e}")
            import traceback
            logger.error(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
            return {'error': str(e)}
    
    def _create_simple_cli(self, economic_data: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        """
        Cria CLI simples se nÃ£o disponÃ­vel
        """
        try:
            logger.info("ğŸ”§ DEBUG: Criando CLI simples")
            logger.info(f"ğŸ“Š SÃ©ries disponÃ­veis: {list(economic_data.keys())}")
            
            # Combinar sÃ©ries econÃ´micas
            combined_data = pd.DataFrame()
            
            for series_name, df in economic_data.items():
                logger.debug(f"ğŸ“Š Processando sÃ©rie: {series_name}")
                if 'value' in df.columns:
                    combined_data[series_name] = df['value']
                    logger.debug(f"âœ… SÃ©rie {series_name} adicionada: {len(df)} pontos")
                else:
                    logger.warning(f"âš ï¸ SÃ©rie {series_name} nÃ£o tem coluna 'value'")
            
            logger.info(f"ğŸ“Š Dados combinados: {combined_data.shape}")
            
            # Normalizar e calcular mÃ©dia
            if not combined_data.empty:
                logger.info("ğŸ“Š Normalizando dados...")
                normalized_data = combined_data.apply(lambda x: (x - x.mean()) / x.std())
                cli_simple = normalized_data.mean(axis=1)
                
                logger.info(f"âœ… CLI simples criado: {len(cli_simple)} pontos")
                logger.info(f"ğŸ“ˆ CLI range: {cli_simple.min():.2f} a {cli_simple.max():.2f}")
                
                # Usar dados reais disponÃ­veis (sem simulaÃ§Ã£o)
                logger.info(f"âœ… CLI simples criado com dados reais: {len(cli_simple)} pontos")
                return pd.DataFrame({
                    'value': cli_simple
                })
            else:
                logger.error("âŒ Nenhum dado disponÃ­vel para criar CLI")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"âŒ ERRO ao criar CLI simples: {e}")
            import traceback
            logger.error(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
            return pd.DataFrame()
    
    def _calculate_yield_signals(self, yield_data: Optional[Dict[str, pd.DataFrame]]) -> Dict:
        """
        Calcula sinais de curva de juros
        """
        try:
            if yield_data is None or not yield_data:
                return {'signals': pd.DataFrame(), 'summary': {}}
            
            # Calcular spreads
            spreads_df = self.yield_indicators.calculate_spreads(yield_data)
            
            if spreads_df.empty:
                return {'signals': pd.DataFrame(), 'summary': {}}
            
            # Gerar sinais
            signals_df = self.yield_indicators.generate_signals(spreads_df)
            
            # Gerar resumo
            summary = self.yield_indicators.get_yield_summary(spreads_df)
            
            return {
                'signals': signals_df,
                'summary': summary
            }
            
        except Exception as e:
            logger.error(f"Erro ao calcular sinais de curva de juros: {e}")
            return {'signals': pd.DataFrame(), 'summary': {}}
    
    def _generate_probabilistic_signals(self, 
                                       markov_results: Dict, 
                                       yield_signals: Dict,
                                       asset_returns: pd.DataFrame) -> pd.DataFrame:
        """
        Gera sinais probabilÃ­sticos integrados
        """
        try:
            logger.info("ğŸ¯ DEBUG: Iniciando geraÃ§Ã£o de sinais probabilÃ­sticos")
            logger.info(f"ğŸ“Š Asset returns: {len(asset_returns)} pontos")
            logger.info(f"ğŸ§  Markov results keys: {list(markov_results.keys())}")
            logger.info(f"ğŸ“ˆ Yield signals keys: {list(yield_signals.keys())}")
            
            # Preparar dados base
            dates = asset_returns.index
            # Garantir que as datas sÃ£o naive (sem timezone)
            if hasattr(dates, 'tz') and dates.tz is not None:
                dates = dates.tz_localize(None)
            signals_df = pd.DataFrame(index=dates)
            logger.info(f"ğŸ“… Datas preparadas: {len(dates)} pontos")
            
            # Sinais do modelo Markov-Switching
            if 'regime_probabilities' in markov_results:
                regime_probs = markov_results['regime_probabilities']
                most_likely_regime = markov_results['most_likely_regime']
                logger.info(f"ğŸ“Š Regime probabilities shape: {regime_probs.shape}")
                logger.info(f"ğŸ“Š Regime probabilities type: {type(regime_probs)}")
                logger.info(f"ğŸ† Most likely regime shape: {most_likely_regime.shape}")
                logger.info(f"ğŸ† Most likely regime type: {type(most_likely_regime)}")
                logger.info(f"ğŸ“Š Signals_df index length: {len(signals_df)}")
                logger.info(f"ğŸ“Š Signals_df index type: {type(signals_df.index)}")
                logger.info(f"ğŸ“Š First few regime probs: {regime_probs[:3] if len(regime_probs) > 0 else 'Empty'}")
                logger.info(f"ğŸ“Š First few most likely: {most_likely_regime[:3] if len(most_likely_regime) > 0 else 'Empty'}")
                
                # Verificar alinhamento de tamanhos - usar o menor tamanho disponÃ­vel
                min_len = min(len(regime_probs), len(signals_df))
                logger.info(f"ğŸ“Š Alinhando dados para tamanho mÃ­nimo: {min_len}")
                
                if len(regime_probs) != len(signals_df):
                    logger.warning(f"âš ï¸ Tamanho incompatÃ­vel: regime_probs={len(regime_probs)}, signals_df={len(signals_df)}")
                    
                    # Usar o tamanho mÃ­nimo para evitar problemas
                    regime_probs = regime_probs[:min_len]
                    most_likely_regime = most_likely_regime[:min_len]
                    signals_df = signals_df.iloc[:min_len].copy()
                    
                    logger.info(f"ğŸ“Š Dados alinhados para {min_len} pontos")
                    logger.info(f"ğŸ“Š regime_probs: {regime_probs.shape}")
                    logger.info(f"ğŸ“Š most_likely_regime: {most_likely_regime.shape}")
                    logger.info(f"ğŸ“Š signals_df: {signals_df.shape}")
                
                # Adicionar probabilidades de regime
                for i, regime_name in enumerate(markov_results['regime_names']):
                    signals_df[f'prob_{regime_name}'] = regime_probs[:, i]
                    logger.debug(f"ğŸ“Š Adicionada probabilidade para regime: {regime_name}")
                
                signals_df['most_likely_regime'] = most_likely_regime
                signals_df['regime_confidence'] = np.max(regime_probs, axis=1)
                logger.info(f"âœ… Sinais Markov adicionados: {len(signals_df.columns)} colunas")
            else:
                logger.warning("âš ï¸ 'regime_probabilities' nÃ£o encontrado em markov_results")
                logger.info(f"ğŸ“Š Markov results keys: {list(markov_results.keys())}")
                # Criar colunas padrÃ£o com valores realistas
                n_points = len(signals_df)
                signals_df['prob_EXPANSION'] = np.full(n_points, 0.3)
                signals_df['prob_RECESSION'] = np.full(n_points, 0.2)
                signals_df['prob_RECOVERY'] = np.full(n_points, 0.3)
                signals_df['prob_CONTRACTION'] = np.full(n_points, 0.2)
                signals_df['most_likely_regime'] = np.full(n_points, 0)  # EXPANSION
                signals_df['regime_confidence'] = np.full(n_points, 0.3)
                signals_df['yield_combined_signal'] = np.full(n_points, 0.0)  # Adicionar coluna padrÃ£o
                logger.info(f"ğŸ“Š Criadas colunas padrÃ£o para {n_points} pontos")
            
            # Sinais de curva de juros
            if not yield_signals['signals'].empty:
                yield_df = yield_signals['signals']
                
                # Alinhar datas
                common_dates = dates.intersection(yield_df.index)
                if len(common_dates) > 0:
                    for col in yield_df.columns:
                        if col in ['buy_signal', 'sell_signal', 'combined_signal', 'signal_strength']:
                            signals_df.loc[common_dates, f'yield_{col}'] = yield_df.loc[common_dates, col]
            
            # Calcular sinais probabilÃ­sticos
            logger.info("ğŸ¯ Calculando sinais probabilÃ­sticos...")
            logger.info(f"ğŸ“Š Signals_df antes: {signals_df.shape}")
            logger.info(f"ğŸ“Š Columns antes: {list(signals_df.columns)}")
            
            signals_df = self._calculate_probabilistic_signals(signals_df)
            
            logger.info(f"ğŸ“Š Signals_df depois: {signals_df.shape}")
            logger.info(f"ğŸ“Š Columns depois: {list(signals_df.columns)}")
            
            return signals_df
            
        except Exception as e:
            logger.error(f"Erro ao gerar sinais probabilÃ­sticos: {e}")
            return pd.DataFrame()
    
    def _calculate_probabilistic_signals(self, signals_df: pd.DataFrame) -> pd.DataFrame:
        """
        Calcula sinais probabilÃ­sticos baseados em mÃºltiplos indicadores
        """
        try:
            logger.info("ğŸ¯ DEBUG: Calculando sinais probabilÃ­sticos")
            logger.info(f"ğŸ“Š Input shape: {signals_df.shape}")
            logger.info(f"ğŸ“Š Available columns: {list(signals_df.columns)}")
            logger.info(f"ğŸ“Š Weights: {self.weights}")
            
            # Sinal de compra probabilÃ­stico
            buy_probability = np.zeros(len(signals_df))
            logger.info("ğŸ“Š Iniciando cÃ¡lculo de buy_probability")
            
            # ContribuiÃ§Ã£o do regime
            if 'prob_EXPANSION' in signals_df.columns:
                expansion_probs = signals_df['prob_EXPANSION']
                regime_contrib = self.weights['regime_probability'] * expansion_probs
                buy_probability += regime_contrib
                logger.info(f"ğŸ“Š Regime contribution: {regime_contrib.mean():.3f} (mean)")
            else:
                logger.warning("âš ï¸ Coluna 'prob_EXPANSION' nÃ£o encontrada")
            
            # ContribuiÃ§Ã£o da curva de juros
            if 'yield_combined_signal' in signals_df.columns:
                yield_signal = signals_df['yield_combined_signal']
                yield_contribution = np.where(yield_signal > 0, yield_signal, 0)
                buy_probability += self.weights['yield_curve'] * yield_contribution
                logger.info(f"ğŸ“Š Yield contribution: {np.mean(yield_contribution):.3f} (mean)")
            else:
                logger.warning("âš ï¸ Coluna 'yield_combined_signal' nÃ£o encontrada")
            
            # ContribuiÃ§Ã£o do momentum
            if 'regime_confidence' in signals_df.columns:
                momentum_contribution = signals_df['regime_confidence']
                buy_probability += self.weights['momentum'] * momentum_contribution
                logger.info(f"ğŸ“Š Momentum contribution: {momentum_contribution.mean():.3f} (mean)")
            else:
                logger.warning("âš ï¸ Coluna 'regime_confidence' nÃ£o encontrada")
            
            # Sinal de venda probabilÃ­stico
            sell_probability = np.zeros(len(signals_df))
            
            # ContribuiÃ§Ã£o do regime
            if 'prob_RECESSION' in signals_df.columns:
                sell_probability += self.weights['regime_probability'] * signals_df['prob_RECESSION']
            
            # ContribuiÃ§Ã£o da curva de juros
            if 'yield_combined_signal' in signals_df.columns:
                yield_signal = signals_df['yield_combined_signal']
                yield_contribution = np.where(yield_signal < 0, -yield_signal, 0)
                sell_probability += self.weights['yield_curve'] * yield_contribution
            
            # Sinais finais
            logger.info(f"ğŸ“Š Buy probability type: {type(buy_probability)}")
            logger.info(f"ğŸ“Š Sell probability type: {type(sell_probability)}")
            
            if hasattr(buy_probability, 'min'):
                logger.info(f"ğŸ“Š Buy probability range: {buy_probability.min():.3f} a {buy_probability.max():.3f}")
            else:
                logger.info(f"ğŸ“Š Buy probability value: {buy_probability}")
                
            if hasattr(sell_probability, 'min'):
                logger.info(f"ğŸ“Š Sell probability range: {sell_probability.min():.3f} a {sell_probability.max():.3f}")
            else:
                logger.info(f"ğŸ“Š Sell probability value: {sell_probability}")
                
            logger.info(f"ğŸ“Š Confidence threshold: {self.confidence_threshold}")
            
            signals_df['buy_probability'] = buy_probability
            signals_df['sell_probability'] = sell_probability
            signals_df['net_signal'] = buy_probability - sell_probability
            
            # Sinais binÃ¡rios
            buy_condition = buy_probability > self.confidence_threshold
            sell_condition = sell_probability > self.confidence_threshold
            hold_condition = (buy_probability <= self.confidence_threshold) & (sell_probability <= self.confidence_threshold)
            
            logger.info(f"ğŸ“Š Buy condition type: {type(buy_condition)}")
            logger.info(f"ğŸ“Š Buy condition shape: {buy_condition.shape if hasattr(buy_condition, 'shape') else 'N/A'}")
            
            signals_df['buy_signal'] = buy_condition.astype(int)
            signals_df['sell_signal'] = sell_condition.astype(int)
            signals_df['hold_signal'] = hold_condition.astype(int)
            
            # Sinal final
            signals_df['final_signal'] = 0
            signals_df.loc[signals_df['buy_signal'] == 1, 'final_signal'] = 1
            signals_df.loc[signals_df['sell_signal'] == 1, 'final_signal'] = -1
            
            logger.info(f"âœ… Sinais calculados: {signals_df.shape}")
            logger.info(f"ğŸ“Š Buy signals: {signals_df['buy_signal'].sum()}")
            logger.info(f"ğŸ“Š Sell signals: {signals_df['sell_signal'].sum()}")
            logger.info(f"ğŸ“Š Hold signals: {signals_df['hold_signal'].sum()}")
            
            return signals_df
            
        except Exception as e:
            logger.error(f"Erro ao calcular sinais probabilÃ­sticos: {e}")
            return signals_df
    
    def _apply_regime_confirmation(self, signals_df: pd.DataFrame) -> pd.DataFrame:
        """
        Aplica confirmaÃ§Ã£o de regime para reduzir over-trading
        """
        try:
            logger.info("ğŸ”’ DEBUG: Aplicando confirmaÃ§Ã£o de regime")
            logger.info(f"ğŸ“Š Signals shape: {signals_df.shape}")
            logger.info(f"ğŸ“Š Columns: {list(signals_df.columns)}")
            
            confirmed_signals = signals_df.copy()
            
            # Verificar se a coluna existe
            if 'most_likely_regime' not in confirmed_signals.columns:
                logger.warning("âš ï¸ Coluna 'most_likely_regime' nÃ£o encontrada, pulando confirmaÃ§Ã£o")
                return confirmed_signals
            
            logger.info(f"ğŸ”’ Aplicando confirmaÃ§Ã£o de regime com {self.regime_confirmation_months} meses")
            
            # Aplicar confirmaÃ§Ã£o de regime
            for i in range(len(confirmed_signals)):
                if i < self.regime_confirmation_months:
                    continue
                
                # Verificar estabilidade do regime
                recent_regimes = confirmed_signals['most_likely_regime'].iloc[i-self.regime_confirmation_months:i+1]
                regime_stable = len(recent_regimes.unique()) == 1
                
                if not regime_stable:
                    # Se regime nÃ£o estÃ¡vel, manter HOLD
                    confirmed_signals.loc[confirmed_signals.index[i], 'final_signal'] = 0
                    logger.debug(f"ğŸ”’ Regime instÃ¡vel no ponto {i}, sinal alterado para HOLD")
            
            logger.info("âœ… ConfirmaÃ§Ã£o de regime aplicada com sucesso")
            return confirmed_signals
            
        except Exception as e:
            logger.error(f"âŒ ERRO na confirmaÃ§Ã£o de regime: {e}")
            import traceback
            logger.error(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
            return signals_df
    
    def _calculate_hrp_allocation(self, 
                                 asset_returns: pd.DataFrame, 
                                 signals_df: pd.DataFrame) -> Dict:
        """
        Calcula alocaÃ§Ã£o HRP baseada nos sinais
        """
        try:
            # Preparar dados para HRP
            returns_clean = asset_returns.dropna()
            
            if returns_clean.empty:
                return {'error': 'Dados de retorno insuficientes'}
            
            # Calcular alocaÃ§Ã£o HRP
            hrp_results = self.hrp_allocator.allocate_portfolio(returns_clean)
            
            return hrp_results
            
        except Exception as e:
            logger.error(f"Erro na alocaÃ§Ã£o HRP: {e}")
            return {'error': str(e)}
    
    def _generate_signal_summary(self, 
                                signals_df: pd.DataFrame, 
                                hrp_allocation: Dict,
                                markov_results: Dict) -> Dict:
        """
        Gera resumo dos sinais
        """
        try:
            logger.info("ğŸ“‹ DEBUG: Gerando resumo dos sinais")
            logger.info(f"ğŸ“Š Signals shape: {signals_df.shape}")
            logger.info(f"ğŸ“Š Signals columns: {list(signals_df.columns)}")
            logger.info(f"ğŸ’° HRP allocation keys: {list(hrp_allocation.keys())}")
            logger.info(f"ğŸ§  Markov results keys: {list(markov_results.keys())}")
            
            if signals_df.empty:
                logger.error("âŒ DataFrame de sinais vazio")
                return {'error': 'Nenhum sinal gerado'}
            
            # EstatÃ­sticas bÃ¡sicas
            total_signals = len(signals_df)
            logger.info(f"ğŸ“Š Total signals: {total_signals}")
            
            # Verificar se as colunas existem antes de acessÃ¡-las
            buy_signals = signals_df['buy_signal'].sum() if 'buy_signal' in signals_df.columns else 0
            sell_signals = signals_df['sell_signal'].sum() if 'sell_signal' in signals_df.columns else 0
            hold_signals = signals_df['hold_signal'].sum() if 'hold_signal' in signals_df.columns else 0
            
            logger.info(f"ğŸ“Š Buy signals: {buy_signals}")
            logger.info(f"ğŸ“Š Sell signals: {sell_signals}")
            logger.info(f"ğŸ“Š Hold signals: {hold_signals}")
            
            # ConfianÃ§a mÃ©dia
            avg_confidence = signals_df['regime_confidence'].mean() if 'regime_confidence' in signals_df.columns else 0
            
            # Probabilidades mÃ©dias
            avg_buy_prob = signals_df['buy_probability'].mean()
            avg_sell_prob = signals_df['sell_probability'].mean()
            
            # Resumo dos regimes
            regime_summary = {}
            if 'regime_names' in markov_results:
                for regime_name in markov_results['regime_names']:
                    prob_col = f'prob_{regime_name}'
                    if prob_col in signals_df.columns:
                        regime_summary[regime_name] = {
                            'avg_probability': float(signals_df[prob_col].mean()),
                            'max_probability': float(signals_df[prob_col].max()),
                            'frequency': float((signals_df[prob_col] > 0.5).sum() / total_signals)
                        }
            
            summary = {
                'total_signals': total_signals,
                'buy_signals': int(buy_signals),
                'sell_signals': int(sell_signals),
                'hold_signals': int(hold_signals),
                'buy_percentage': float(buy_signals / total_signals * 100),
                'sell_percentage': float(sell_signals / total_signals * 100),
                'hold_percentage': float(hold_signals / total_signals * 100),
                'avg_confidence': float(avg_confidence),
                'avg_buy_probability': float(avg_buy_prob),
                'avg_sell_probability': float(avg_sell_prob),
                'regime_summary': regime_summary,
                'hrp_allocation': hrp_allocation.get('allocation', {}),
                'hrp_metrics': hrp_allocation.get('metrics', {})
            }
            
            logger.info(f"âœ… Resumo gerado com sucesso: {len(summary)} mÃ©tricas")
            logger.info(f"ğŸ“Š Total signals: {summary['total_signals']}")
            logger.info(f"ğŸ“Š Buy percentage: {summary['buy_percentage']:.1f}%")
            logger.info(f"ğŸ“Š Sell percentage: {summary['sell_percentage']:.1f}%")
            logger.info(f"ğŸ¯ Avg confidence: {summary['avg_confidence']:.3f}")
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ ERRO ao gerar resumo: {e}")
            import traceback
            logger.error(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
            return {'error': str(e)}

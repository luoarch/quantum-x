# ü•à Roadmap para Prata (Silver) - API FED-Selic

**Data de In√≠cio:** 30 de Setembro de 2025  
**Dura√ß√£o Estimada:** 6-8 semanas  
**Vers√£o do Projeto:** 2.0 (Quantum-X)

---

## üéØ Objetivo

**Elevar a maturidade da API de Bronze (90-95%) para Prata (‚â•85%), habilitando uso interno amplo com qualidade de produ√ß√£o, observabilidade completa, gates autom√°ticos e can√°rio.**

---

## üìä Status Atual (P√≥s-Sprint 1)

| Categoria | Status Atual | Target Prata | Gap |
|-----------|--------------|--------------|-----|
| **Foundation e Dados** | 85% | 90% | 5% |
| **Modelagem e Treino** | 100% | 100% | 0% ‚úÖ |
| **Valida√ß√£o Cient√≠fica** | 85% | 95% | 10% |
| **API e Contratos** | 95% | 95% | 0% ‚úÖ |
| **MLOps** | 75% | 95% | 20% |
| **Observabilidade** | 70% | 95% | 25% üî¥ |
| **Seguran√ßa** | 80% | 95% | 15% |
| **Performance** | 0% | 90% | 90% üî¥ |
| **Testes** | 0% | 85% | 85% üî¥ |
| **UAT/Rollout** | 0% | 80% | 80% üî¥ |

**üî¥ GAPS CR√çTICOS PARA PRATA:**
1. Observabilidade (Prometheus, dashboards)
2. Performance (m√©tricas, testes de carga)
3. Testes (unit√°rios, integra√ß√£o, e2e)
4. UAT (casos documentados e assinados)
5. MLOps (CI/CD, gates autom√°ticos)

---

## üóìÔ∏è Roadmap por Sprints

### üì¶ **Sprint 2: Completar Bronze 100% (Semanas 4-5)**

**Objetivo:** Completar os √∫ltimos 5-10% do Bronze para habilitar certifica√ß√£o completa.

**Dura√ß√£o:** 2 semanas  
**Prioridade:** üî¥ CR√çTICA

#### **2.1 Testes Automatizados (Semana 4)**

**üéØ Meta: Cobertura ‚â•80%**

##### **Dia 1-2: Setup de Testes**
- [ ] Configurar pytest + pytest-cov
- [ ] Setup fixtures para modelos, dados, API
- [ ] Configurar pytest.ini com plugins
- [ ] Criar estrutura tests/unit/ e tests/integration/

##### **Dia 3-4: Testes Unit√°rios (Core)**
- [ ] **Schemas (15 testes)**
  - Valida√ß√£o de PredictionRequest
  - Valida√ß√£o de BatchError
  - Validators (fed_move_bps % 25, consistency)
- [ ] **ModelService (12 testes)**
  - load_model(), get_active_version()
  - Cache LRU (eviction, max size)
  - Self-checks (estabilidade, dimens√µes)
- [ ] **PredictionService (18 testes)**
  - Discretiza√ß√£o anal√≠tica
  - Normaliza√ß√£o (sum=1.0)
  - Decay adaptativo
  - Copom mapping

##### **Dia 5: Testes Unit√°rios (Modelos)**
- [ ] **BVAR (10 testes)**
  - Estabilidade (eigenvalues)
  - IRF normalization
  - Conditional forecast consistency
  - Prior scaling
- [ ] **LP (8 testes)**
  - Bootstrap CI coverage
  - Horizons ordering
  - Shrinkage effect

**Entreg√°vel:** ‚â•80% cobertura em src/

---

#### **2.2 Observabilidade Completa (Semana 5)**

**üéØ Meta: Prometheus + Grafana operacionais**

##### **Dia 1-2: Prometheus Instrumenta√ß√£o**
- [ ] Adicionar `prometheus-fastapi-instrumentator`
- [ ] Expor `/metrics` endpoint
- [ ] M√©tricas autom√°ticas:
  - `http_request_duration_seconds` (p50, p95, p99)
  - `http_requests_total` (por status, endpoint)
  - `http_request_size_bytes`, `http_response_size_bytes`
- [ ] M√©tricas customizadas:
  - `prediction_requests_total` (por model_version)
  - `prediction_latency_seconds` (por horizonte)
  - `model_load_duration_seconds`
  - `cache_hit_ratio`

##### **Dia 3: Grafana Dashboards**
- [ ] Setup docker-compose.observability.yml
  - Prometheus (scrape /metrics a cada 15s)
  - Grafana (dashboards pr√©-configurados)
- [ ] Dashboard 1: HTTP Metrics
  - Request rate, latency (p50/p95/p99), errors
- [ ] Dashboard 2: Business Metrics
  - Predictions por vers√£o, lat√™ncia por horizonte
  - Cache hit rate, modelo ativo
- [ ] Dashboard 3: System Health
  - CPU, mem√≥ria, uptime

##### **Dia 4-5: Logging Estruturado Completo**
- [ ] Configurar structlog
- [ ] Adicionar campos obrigat√≥rios em todos logs:
  - `request_id`, `model_version`, `data_hash`, `action`, `success`
- [ ] Implementar log levels consistentes
- [ ] Configurar rota√ß√£o de logs (10MB, 5 arquivos)
- [ ] Setup ELK stack opcional (dev)

**Entreg√°vel:** Observabilidade production-ready

---

### üèóÔ∏è **Sprint 3: Performance e Seguran√ßa (Semanas 6-7)**

**Objetivo:** Validar SLOs de performance e hardening de seguran√ßa.

**Dura√ß√£o:** 2 semanas  
**Prioridade:** üî¥ CR√çTICA

#### **3.1 Performance e SLOs (Semana 6)**

##### **Dia 1-2: Setup de Testes de Carga**
- [ ] Instalar Locust ou k6
- [ ] Criar cen√°rios de carga:
  - Scenario 1: 10 RPS steady (5 min)
  - Scenario 2: 50 RPS ramp-up (10 min)
  - Scenario 3: Spike test (100 RPS por 2 min)
- [ ] Configurar coleta de m√©tricas (p50/p95/p99)

##### **Dia 3: Execu√ß√£o e Otimiza√ß√£o**
- [ ] Executar baseline (sem otimiza√ß√µes)
- [ ] Identificar gargalos (profiling)
- [ ] Otimiza√ß√µes:
  - Lazy loading de modelos
  - Cache de discretiza√ß√£o
  - Async I/O onde aplic√°vel
- [ ] Re-executar e validar **p95 < 250ms**

##### **Dia 4-5: Monitoramento Cont√≠nuo**
- [ ] Configurar alertas Prometheus:
  - `http_request_duration_seconds{quantile="0.95"} > 0.250`
  - `http_requests_total{status=~"5.."} / rate(5m) > 0.01`
- [ ] Setup Alertmanager (notifica√ß√µes via webhook/email)
- [ ] Runbook b√°sico para degrada√ß√£o de performance

**Entreg√°vel:** p95 < 250ms validado e monitorado

---

#### **3.2 Seguran√ßa Hardened (Semana 7)**

##### **Dia 1-2: TLS e HTTPS**
- [ ] Gerar certificado autoassinado (dev)
- [ ] Configurar Uvicorn com SSL
- [ ] Testar endpoints via HTTPS
- [ ] Documentar setup de certificados (prod)

##### **Dia 3: Secrets Management**
- [ ] Implementar loading de API keys de vari√°vel de ambiente
- [ ] Criar `.env.example` com chaves dummy
- [ ] Validar que API_KEYS n√£o est√£o hardcoded
- [ ] Opcional: Setup Vault/AWS Secrets Manager

##### **Dia 4-5: Security Headers e Rate Limiting**
- [ ] Validar headers de seguran√ßa:
  - `X-Content-Type-Options: nosniff`
  - `X-Frame-Options: DENY`
  - `Strict-Transport-Security` (HSTS)
- [ ] Testar rate limiting (429 responses)
- [ ] Audit de depend√™ncias (safety check)
- [ ] OWASP Top 10 checklist

**Entreg√°vel:** Seguran√ßa hardened para piloto amplo

---

### üß™ **Sprint 4: UAT e Certifica√ß√£o Bronze (Semana 8)**

**Objetivo:** Executar UAT, documentar, assinar e certificar Bronze 100%.

**Dura√ß√£o:** 1 semana  
**Prioridade:** üî¥ CR√çTICA

##### **Dia 1-2: Definir Casos de UAT**
- [ ] **Caso 1:** Fed +25 bps (hawkish)
  - Request: `{"fed_move_bps": 25, "fed_move_dir": "1", ...}`
  - Validar: distribution, CI80/95, rationale
- [ ] **Caso 2:** Fed 0 bps (neutral)
  - Validar: probabilidade maior em delta=0
- [ ] **Caso 3:** Fed -25 bps (dovish)
  - Validar: resposta negativa da Selic
- [ ] **Caso 4:** Fed +50 bps (shock)
  - Validar: CI95 amplo, incerteza alta
- [ ] **Caso 5:** Fed +25 bps com surpresa de +10 bps
  - Validar: impacto adicional no modelo

##### **Dia 3-4: Executar UAT**
- [ ] Ambiente: staging com modelo v1.0.2
- [ ] Executar 5 casos via Postman/curl
- [ ] Documentar resultados:
  - Screenshots de responses
  - Logs estruturados
  - M√©tricas de lat√™ncia
  - An√°lise qualitativa (rationale faz sentido?)

##### **Dia 5: Documenta√ß√£o e Assinatura**
- [ ] Criar `UAT_REPORT.md`:
  - Casos executados
  - Resultados observados vs esperados
  - Desvios e explica√ß√µes
  - Aprova√ß√£o ou ajustes necess√°rios
- [ ] Assinar UAT (aprova√ß√£o formal)
- [ ] **üèÜ CERTIFICAR BRONZE 100%**

**Entreg√°vel:** Bronze certificado com UAT assinado

---

### ü•à **Sprints 5-7: Prata (Semanas 9-14)**

**Objetivo:** Implementar gates autom√°ticos, CI/CD, alertas e can√°rio para atingir Prata.

**Dura√ß√£o:** 6 semanas  
**Prioridade:** üü° ALTA

---

#### **Sprint 5: Gates de Qualidade Autom√°ticos (Semanas 9-10)**

##### **5.1 Gate de Cobertura CI**
- [ ] Calcular cobertura CI95 em backtest hist√≥rico
- [ ] Threshold: cobertura ‚â•85%
- [ ] Gate autom√°tico: bloquear promo√ß√£o se < 85%
- [ ] M√©tricas adicionais:
  - Brier Score (vs baseline random)
  - CRPS (Continuous Ranked Probability Score)

##### **5.2 Gate de Estabilidade**
- [ ] Verificar eigenvalues BVAR < 1.0
- [ ] Verificar IRF converg√™ncia (decaimento exponencial)
- [ ] Bloquear se modelo inst√°vel

##### **5.3 Gate de Performance**
- [ ] Executar mini load test (10 RPS, 1 min)
- [ ] Threshold: p95 < 250ms
- [ ] Bloquear se exceder

**Entreg√°vel:** 3 gates autom√°ticos funcionais

---

#### **Sprint 6: CI/CD e Registro de Modelos (Semanas 11-12)**

##### **6.1 GitHub Actions Pipeline**
- [ ] `.github/workflows/ci.yml`:
  - Lint (ruff, black)
  - Testes (pytest com coverage ‚â•80%)
  - Gates cient√≠ficos (estabilidade, cobertura CI)
  - Build de artefatos
- [ ] `.github/workflows/cd.yml`:
  - Deploy para staging (autom√°tico em merge para main)
  - Deploy para prod (manual approval)

##### **6.2 Registro de Modelos**
- [ ] Implementar `ModelRegistry` service
- [ ] Armazenar artefatos versionados:
  - `models/v{version}/model_lp.pkl`
  - `models/v{version}/model_bvar.pkl`
  - `models/v{version}/metadata.json`
  - `models/v{version}/validation_report.json`
- [ ] API para promo√ß√£o:
  - `/models/{version}/promote` (staging ‚Üí prod)
  - Validar gates antes de promover

##### **6.3 Versionamento Sem√¢ntico**
- [ ] Implementar auto-bump de vers√£o:
  - Major: quebra de contrato
  - Minor: nova feature (regime hint, etc.)
  - Patch: bugfix
- [ ] Tag Git autom√°tico

**Entreg√°vel:** CI/CD completo com registro de modelos

---

#### **Sprint 7: Alertas, RBAC e Can√°rio (Semanas 13-14)**

##### **7.1 Alertmanager e Runbooks**
- [ ] Configurar Alertmanager
- [ ] Alertas cr√≠ticos:
  - `HighLatency` (p95 > 250ms por 5 min)
  - `HighErrorRate` (5xx > 1% por 5 min)
  - `ModelLoadFailure` (startup failure)
- [ ] Runbooks para cada alerta:
  - Diagn√≥stico
  - Mitiga√ß√£o
  - Escala√ß√£o

##### **7.2 RBAC B√°sico**
- [ ] N√≠veis de acesso:
  - `viewer`: read-only (GET /predict, /health)
  - `operator`: manage models (POST /models/activate)
  - `admin`: full access (DELETE, config)
- [ ] Implementar no AuthenticationMiddleware
- [ ] Documentar permiss√µes

##### **7.3 Deploy Can√°rio**
- [ ] Implementar estrat√©gia de can√°rio:
  - 10% tr√°fego para nova vers√£o (30 min)
  - Monitorar: lat√™ncia, erros, m√©tricas de neg√≥cio
  - Auto-rollback se:
    - Error rate > 2x baseline
    - Latency p95 > 1.5x baseline
- [ ] Script de rollback manual
- [ ] Testar can√°rio em staging

**Entreg√°vel:** Can√°rio funcional com auto-rollback

---

## üèÜ Crit√©rios de Aceita√ß√£o - Prata

### ‚úÖ **Checklist Prata (85% em todos pilares)**

| # | Crit√©rio | Target | Status |
|---|----------|--------|--------|
| 1 | **Testes unit√°rios** | ‚â•80% coverage | ‚è≥ Sprint 2 |
| 2 | **Testes integra√ß√£o** | ‚â•20 cen√°rios e2e | ‚è≥ Sprint 2 |
| 3 | **Performance p95** | <250ms validado | ‚è≥ Sprint 3 |
| 4 | **Observabilidade** | Prometheus + Grafana | ‚è≥ Sprint 2 |
| 5 | **Logging estruturado** | Todos campos obrigat√≥rios | ‚è≥ Sprint 2 |
| 6 | **Seguran√ßa TLS** | HTTPS em staging/prod | ‚è≥ Sprint 3 |
| 7 | **Secrets management** | Env vars ou Vault | ‚è≥ Sprint 3 |
| 8 | **UAT assinado** | 5 casos executados | ‚è≥ Sprint 4 |
| 9 | **Gates autom√°ticos** | 3 gates funcionais | ‚è≥ Sprint 5 |
| 10 | **CI/CD** | GitHub Actions completo | ‚è≥ Sprint 6 |
| 11 | **Registro de modelos** | Versionamento autom√°tico | ‚è≥ Sprint 6 |
| 12 | **Alertas** | Alertmanager + runbooks | ‚è≥ Sprint 7 |
| 13 | **RBAC** | 3 n√≠veis de acesso | ‚è≥ Sprint 7 |
| 14 | **Can√°rio** | Auto-rollback funcional | ‚è≥ Sprint 7 |
| 15 | **Disponibilidade** | 99.95% em staging (2 semanas) | ‚è≥ Sprint 7 |

---

## üìä M√©tricas de Progresso

### **Tabela de Evolu√ß√£o**

| M√©trica | Bronze | Prata Target | Status Atual |
|---------|--------|--------------|--------------|
| **Cobertura Testes** | 80% | 85% | 0% ‚Üí 85% üî¥ |
| **Lat√™ncia P95** | <250ms | <200ms | - ‚Üí 180ms ‚è≥ |
| **Disponibilidade** | 99.9% | 99.95% | - ‚Üí 99.95% ‚è≥ |
| **Gates Ativos** | 0 | 3 | 0 ‚Üí 3 üî¥ |
| **Runbooks** | 1 | 3 | 0 ‚Üí 3 üî¥ |
| **Ambientes** | 2 (dev, staging) | 3 (+ prod) | 2 ‚Üí 3 ‚è≥ |
| **Cobertura CI95** | ‚â•85% | ‚â•90% | - ‚Üí 90% üî¥ |
| **MTTR (Mean Time to Restore)** | - | <30min | - ‚Üí 25min ‚è≥ |

---

## üöÄ Plano de Execu√ß√£o

### **Timeline Visual**

```
Semana 4     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚îÇ Testes Unit√°rios
Semana 5     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ Observabilidade
Semana 6     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚îÇ Performance
Semana 7     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ Seguran√ßa
Semana 8     ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ UAT + Cert Bronze
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Semana 9-10  ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ Gates Autom√°ticos
Semana 11-12 ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ CI/CD + Registro
Semana 13-14 ‚îÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚îÇ Alertas + Can√°rio
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
             üèÜ PRATA CERTIFICADO
```

---

## üìù Pr√≥ximos Passos Imediatos

### **üî¥ A√á√ÉO IMEDIATA (Hoje):**
1. ‚úÖ Criar branch `feat/silver-sprint-2-tests`
2. ‚è≥ Setup pytest + pytest-cov
3. ‚è≥ Criar fixtures b√°sicos
4. ‚è≥ Primeiro teste: `test_prediction_request_validation`

### **üìÖ Esta Semana (Semana 4):**
- Completar setup de testes
- Atingir 50% de cobertura em schemas e services
- Documentar estrat√©gia de testes

### **üéØ Este M√™s (Outubro):**
- Completar Sprint 2 e 3
- Certificar Bronze 100%
- Iniciar Sprint 5 (gates)

---

## üéì Li√ß√µes do Sprint 1 Aplicadas

**‚úÖ O que funcionou bem:**
- Foco em qualidade cient√≠fica desde o in√≠cio
- Governan√ßa por headers e logs estruturados
- Fail-soft e graceful degradation

**üîÑ O que melhoraremos:**
- Testes desde o in√≠cio (n√£o deixar para depois)
- Observabilidade early (Prometheus desde Sprint 2)
- Performance testing cont√≠nuo (n√£o s√≥ no final)

---

## üìö Refer√™ncias

- [ANALISE_MATURIDADE.md](./ANALISE_MATURIDADE.md) - An√°lise completa de maturidade
- [REQUISITOS.md](./REQUISITOS.md) - Requisitos funcionais e n√£o-funcionais
- [GO_LIVE_CHECKLIST.md](./GO_LIVE_CHECKLIST.md) - Checklist de go-live
- [MODEL_CARD_v1.0.2.md](./MODEL_CARD_v1.0.2.md) - Valida√ß√£o t√©cnica do modelo

---

**üéä Status:** ROADMAP APROVADO  
**üöÄ Next:** Sprint 2 - Testes e Observabilidade  
**üèÜ Goal:** Prata em 6-8 semanas


# ğŸ¥ˆ Roadmap para Prata (Silver) - API FED-Selic

**Data de InÃ­cio:** 30 de Setembro de 2025  
**DuraÃ§Ã£o Estimada:** 6-8 semanas  
**VersÃ£o do Projeto:** 2.0 (Quantum-X)

---

## ğŸ¯ Objetivo

**Elevar a maturidade da API de Bronze (90-95%) para Prata (â‰¥85%), habilitando uso interno amplo com qualidade de produÃ§Ã£o, observabilidade completa, gates automÃ¡ticos e canÃ¡rio.**

---

## ğŸ“Š Status Atual (PÃ³s-Sprint 1)

| Categoria | Status Atual | Target Prata | Gap |
|-----------|--------------|--------------|-----|
| **Foundation e Dados** | 85% | 90% | 5% |
| **Modelagem e Treino** | 100% | 100% | 0% âœ… |
| **ValidaÃ§Ã£o CientÃ­fica** | 85% | 95% | 10% |
| **API e Contratos** | 95% | 95% | 0% âœ… |
| **MLOps** | 75% | 95% | 20% |
| **Observabilidade** | 70% | 95% | 25% ğŸ”´ |
| **SeguranÃ§a** | 80% | 95% | 15% |
| **Performance** | 0% | 90% | 90% ğŸ”´ |
| **Testes** | 0% | 85% | 85% ğŸ”´ |
| **UAT/Rollout** | 0% | 80% | 80% ğŸ”´ |

**ğŸ”´ GAPS CRÃTICOS PARA PRATA:**
1. Observabilidade (Prometheus, dashboards)
2. Performance (mÃ©tricas, testes de carga)
3. Testes (unitÃ¡rios, integraÃ§Ã£o, e2e)
4. UAT (casos documentados e assinados)
5. MLOps (CI/CD, gates automÃ¡ticos)

---

## ğŸ—“ï¸ Roadmap por Sprints

### ğŸ“¦ **Sprint 2: Completar Bronze 100% (Semanas 4-5)**

**Objetivo:** Completar os Ãºltimos 5-10% do Bronze para habilitar certificaÃ§Ã£o completa.

**DuraÃ§Ã£o:** 2 semanas  
**Prioridade:** ğŸ”´ CRÃTICA

#### **2.1 Testes Automatizados (Semana 4)**

**ğŸ¯ Meta: Cobertura â‰¥80%**

##### **Dia 1-2: Setup de Testes**
- [ ] Configurar pytest + pytest-cov
- [ ] Setup fixtures para modelos, dados, API
- [ ] Configurar pytest.ini com plugins
- [ ] Criar estrutura tests/unit/ e tests/integration/

##### **Dia 3-4: Testes UnitÃ¡rios (Core)**
- [ ] **Schemas (15 testes)**
  - ValidaÃ§Ã£o de PredictionRequest
  - ValidaÃ§Ã£o de BatchError
  - Validators (fed_move_bps % 25, consistency)
- [ ] **ModelService (12 testes)**
  - load_model(), get_active_version()
  - Cache LRU (eviction, max size)
  - Self-checks (estabilidade, dimensÃµes)
- [ ] **PredictionService (18 testes)**
  - DiscretizaÃ§Ã£o analÃ­tica
  - NormalizaÃ§Ã£o (sum=1.0)
  - Decay adaptativo
  - Copom mapping

##### **Dia 5: Testes UnitÃ¡rios (Modelos)**
- [ ] **BVAR (10 testes)**
  - Estabilidade (eigenvalues)
  - IRF normalization
  - Conditional forecast consistency
  - Prior scaling
- [ ] **LP (8 testes)**
  - Bootstrap CI coverage
  - Horizons ordering
  - Shrinkage effect

**EntregÃ¡vel:** â‰¥80% cobertura em src/

---

#### **2.2 Observabilidade Completa (Semana 5)**

**ğŸ¯ Meta: Prometheus + Grafana operacionais**

##### **Dia 1-2: Prometheus InstrumentaÃ§Ã£o**
- [ ] Adicionar `prometheus-fastapi-instrumentator`
- [ ] Expor `/metrics` endpoint
- [ ] MÃ©tricas automÃ¡ticas:
  - `http_request_duration_seconds` (p50, p95, p99)
  - `http_requests_total` (por status, endpoint)
  - `http_request_size_bytes`, `http_response_size_bytes`
- [ ] MÃ©tricas customizadas:
  - `prediction_requests_total` (por model_version)
  - `prediction_latency_seconds` (por horizonte)
  - `model_load_duration_seconds`
  - `cache_hit_ratio`

##### **Dia 3: Grafana Dashboards**
- [ ] Setup docker-compose.observability.yml
  - Prometheus (scrape /metrics a cada 15s)
  - Grafana (dashboards prÃ©-configurados)
- [ ] Dashboard 1: HTTP Metrics
  - Request rate, latency (p50/p95/p99), errors
- [ ] Dashboard 2: Business Metrics
  - Predictions por versÃ£o, latÃªncia por horizonte
  - Cache hit rate, modelo ativo
- [ ] Dashboard 3: System Health
  - CPU, memÃ³ria, uptime

##### **Dia 4-5: Logging Estruturado Completo**
- [ ] Configurar structlog
- [ ] Adicionar campos obrigatÃ³rios em todos logs:
  - `request_id`, `model_version`, `data_hash`, `action`, `success`
- [ ] Implementar log levels consistentes
- [ ] Configurar rotaÃ§Ã£o de logs (10MB, 5 arquivos)
- [ ] Setup ELK stack opcional (dev)

**EntregÃ¡vel:** Observabilidade production-ready

---

### ğŸ—ï¸ **Sprint 3: Performance e SeguranÃ§a (Semanas 6-7)**

**Objetivo:** Validar SLOs de performance e hardening de seguranÃ§a.

**DuraÃ§Ã£o:** 2 semanas  
**Prioridade:** ğŸ”´ CRÃTICA

#### **3.1 Performance e SLOs (Semana 6)**

##### **Dia 1-2: Setup de Testes de Carga**
- [ ] Instalar Locust ou k6
- [ ] Criar cenÃ¡rios de carga:
  - Scenario 1: 10 RPS steady (5 min)
  - Scenario 2: 50 RPS ramp-up (10 min)
  - Scenario 3: Spike test (100 RPS por 2 min)
- [ ] Configurar coleta de mÃ©tricas (p50/p95/p99)

##### **Dia 3: ExecuÃ§Ã£o e OtimizaÃ§Ã£o**
- [ ] Executar baseline (sem otimizaÃ§Ãµes)
- [ ] Identificar gargalos (profiling)
- [ ] OtimizaÃ§Ãµes:
  - Lazy loading de modelos
  - Cache de discretizaÃ§Ã£o
  - Async I/O onde aplicÃ¡vel
- [ ] Re-executar e validar **p95 < 250ms**

##### **Dia 4-5: Monitoramento ContÃ­nuo**
- [ ] Configurar alertas Prometheus:
  - `http_request_duration_seconds{quantile="0.95"} > 0.250`
  - `http_requests_total{status=~"5.."} / rate(5m) > 0.01`
- [ ] Setup Alertmanager (notificaÃ§Ãµes via webhook/email)
- [ ] Runbook bÃ¡sico para degradaÃ§Ã£o de performance

**EntregÃ¡vel:** p95 < 250ms validado e monitorado

---

#### **3.2 SeguranÃ§a Hardened (Semana 7)**

##### **Dia 1-2: TLS e HTTPS**
- [ ] Gerar certificado autoassinado (dev)
- [ ] Configurar Uvicorn com SSL
- [ ] Testar endpoints via HTTPS
- [ ] Documentar setup de certificados (prod)

##### **Dia 3: Secrets Management**
- [ ] Implementar loading de API keys de variÃ¡vel de ambiente
- [ ] Criar `.env.example` com chaves dummy
- [ ] Validar que API_KEYS nÃ£o estÃ£o hardcoded
- [ ] Opcional: Setup Vault/AWS Secrets Manager

##### **Dia 4-5: Security Headers e Rate Limiting**
- [ ] Validar headers de seguranÃ§a:
  - `X-Content-Type-Options: nosniff`
  - `X-Frame-Options: DENY`
  - `Strict-Transport-Security` (HSTS)
- [ ] Testar rate limiting (429 responses)
- [ ] Audit de dependÃªncias (safety check)
- [ ] OWASP Top 10 checklist

**EntregÃ¡vel:** SeguranÃ§a hardened para piloto amplo

---

### ğŸ§ª **Sprint 4: UAT e CertificaÃ§Ã£o Bronze (Semana 8)**

**Objetivo:** Executar UAT, documentar, assinar e certificar Bronze 100%.

**DuraÃ§Ã£o:** 1 semana  
**Prioridade:** ğŸ”´ CRÃTICA

##### **Dia 1-2: Definir Casos de UAT**
- [ ] **Caso 1:** Fed +25 bps (hawkish)
  - Request: `{"fed_move_bps": 25, "fed_move_dir": "1", ...}`
  - Validar: distribution, CI80/95, rationale
- [ ] **Caso 2:** Fed 0 bps (neutral)
  - Validar: probabilidade maior em delta=0
- [ ] **Caso 3:** Fed -25 bps (dovish)
  - Validar: resposta negativa da Selic
- [ ] **Caso 4:** Fed +50 bps (shock)
  - Validar: CI95 amplo, incerteza alta
- [ ] **Caso 5:** Fed +25 bps com surpresa de +10 bps
  - Validar: impacto adicional no modelo

##### **Dia 3-4: Executar UAT**
- [ ] Ambiente: staging com modelo v1.0.2
- [ ] Executar 5 casos via Postman/curl
- [ ] Documentar resultados:
  - Screenshots de responses
  - Logs estruturados
  - MÃ©tricas de latÃªncia
  - AnÃ¡lise qualitativa (rationale faz sentido?)

##### **Dia 5: DocumentaÃ§Ã£o e Assinatura**
- [ ] Criar `UAT_REPORT.md`:
  - Casos executados
  - Resultados observados vs esperados
  - Desvios e explicaÃ§Ãµes
  - AprovaÃ§Ã£o ou ajustes necessÃ¡rios
- [ ] Assinar UAT (aprovaÃ§Ã£o formal)
- [ ] **ğŸ† CERTIFICAR BRONZE 100%**

**EntregÃ¡vel:** Bronze certificado com UAT assinado

---

### ğŸ¥ˆ **Sprints 5-7: Prata (Semanas 9-14)**

**Objetivo:** Implementar gates automÃ¡ticos, CI/CD, alertas e canÃ¡rio para atingir Prata.

**DuraÃ§Ã£o:** 6 semanas  
**Prioridade:** ğŸŸ¡ ALTA

---

#### **Sprint 5: Gates de Qualidade AutomÃ¡ticos (Semanas 9-10)**

##### **5.1 Gate de Cobertura CI**
- [ ] Calcular cobertura CI95 em backtest histÃ³rico
- [ ] Threshold: cobertura â‰¥85%
- [ ] Gate automÃ¡tico: bloquear promoÃ§Ã£o se < 85%
- [ ] MÃ©tricas adicionais:
  - Brier Score (vs baseline random)
  - CRPS (Continuous Ranked Probability Score)

##### **5.2 Gate de Estabilidade**
- [ ] Verificar eigenvalues BVAR < 1.0
- [ ] Verificar IRF convergÃªncia (decaimento exponencial)
- [ ] Bloquear se modelo instÃ¡vel

##### **5.3 Gate de Performance**
- [ ] Executar mini load test (10 RPS, 1 min)
- [ ] Threshold: p95 < 250ms
- [ ] Bloquear se exceder

**EntregÃ¡vel:** 3 gates automÃ¡ticos funcionais

---

#### **Sprint 6: CI/CD e Registro de Modelos (Semanas 11-12)**

##### **6.1 GitHub Actions Pipeline**
- [ ] `.github/workflows/ci.yml`:
  - Lint (ruff, black)
  - Testes (pytest com coverage â‰¥80%)
  - Gates cientÃ­ficos (estabilidade, cobertura CI)
  - Build de artefatos
- [ ] `.github/workflows/cd.yml`:
  - Deploy para staging (automÃ¡tico em merge para main)
  - Deploy para prod (manual approval)

##### **6.2 Registro de Modelos**
- [ ] Implementar `ModelRegistry` service
- [ ] Armazenar artefatos versionados:
  - `models/v{version}/model_lp.pkl`
  - `models/v{version}/model_bvar.pkl`
  - `models/v{version}/metadata.json`
  - `models/v{version}/validation_report.json`
- [ ] API para promoÃ§Ã£o:
  - `/models/{version}/promote` (staging â†’ prod)
  - Validar gates antes de promover

##### **6.3 Versionamento SemÃ¢ntico**
- [ ] Implementar auto-bump de versÃ£o:
  - Major: quebra de contrato
  - Minor: nova feature (regime hint, etc.)
  - Patch: bugfix
- [ ] Tag Git automÃ¡tico

**EntregÃ¡vel:** CI/CD completo com registro de modelos

---

#### **Sprint 7: Alertas, RBAC e CanÃ¡rio (Semanas 13-14)**

##### **7.1 Alertmanager e Runbooks**
- [ ] Configurar Alertmanager
- [ ] Alertas crÃ­ticos:
  - `HighLatency` (p95 > 250ms por 5 min)
  - `HighErrorRate` (5xx > 1% por 5 min)
  - `ModelLoadFailure` (startup failure)
- [ ] Runbooks para cada alerta:
  - DiagnÃ³stico
  - MitigaÃ§Ã£o
  - EscalaÃ§Ã£o

##### **7.2 RBAC BÃ¡sico**
- [ ] NÃ­veis de acesso:
  - `viewer`: read-only (GET /predict, /health)
  - `operator`: manage models (POST /models/activate)
  - `admin`: full access (DELETE, config)
- [ ] Implementar no AuthenticationMiddleware
- [ ] Documentar permissÃµes

##### **7.3 Deploy CanÃ¡rio**
- [ ] Implementar estratÃ©gia de canÃ¡rio:
  - 10% trÃ¡fego para nova versÃ£o (30 min)
  - Monitorar: latÃªncia, erros, mÃ©tricas de negÃ³cio
  - Auto-rollback se:
    - Error rate > 2x baseline
    - Latency p95 > 1.5x baseline
- [ ] Script de rollback manual
- [ ] Testar canÃ¡rio em staging

**EntregÃ¡vel:** CanÃ¡rio funcional com auto-rollback

---

## ğŸ† CritÃ©rios de AceitaÃ§Ã£o - Prata

### âœ… **Checklist Prata (85% em todos pilares)**

| # | CritÃ©rio | Target | Status |
|---|----------|--------|--------|
| 1 | **Testes unitÃ¡rios** | â‰¥80% coverage | â³ Sprint 2 |
| 2 | **Testes integraÃ§Ã£o** | â‰¥20 cenÃ¡rios e2e | â³ Sprint 2 |
| 3 | **Performance p95** | <250ms validado | â³ Sprint 3 |
| 4 | **Observabilidade** | Prometheus + Grafana | â³ Sprint 2 |
| 5 | **Logging estruturado** | Todos campos obrigatÃ³rios | â³ Sprint 2 |
| 6 | **SeguranÃ§a TLS** | HTTPS em staging/prod | â³ Sprint 3 |
| 7 | **Secrets management** | Env vars ou Vault | â³ Sprint 3 |
| 8 | **UAT assinado** | 5 casos executados | â³ Sprint 4 |
| 9 | **Gates automÃ¡ticos** | 3 gates funcionais | â³ Sprint 5 |
| 10 | **CI/CD** | GitHub Actions completo | â³ Sprint 6 |
| 11 | **Registro de modelos** | Versionamento automÃ¡tico | â³ Sprint 6 |
| 12 | **Alertas** | Alertmanager + runbooks | â³ Sprint 7 |
| 13 | **RBAC** | 3 nÃ­veis de acesso | â³ Sprint 7 |
| 14 | **CanÃ¡rio** | Auto-rollback funcional | â³ Sprint 7 |
| 15 | **Disponibilidade** | 99.95% em staging (2 semanas) | â³ Sprint 7 |

---

## ğŸ“Š MÃ©tricas de Progresso

### **Tabela de EvoluÃ§Ã£o**

| MÃ©trica | Bronze | Prata Target | Status Atual |
|---------|--------|--------------|--------------|
| **Cobertura Testes** | 80% | 85% | 0% â†’ 85% ğŸ”´ |
| **LatÃªncia P95** | <250ms | <200ms | - â†’ 180ms â³ |
| **Disponibilidade** | 99.9% | 99.95% | - â†’ 99.95% â³ |
| **Gates Ativos** | 0 | 3 | 0 â†’ 3 ğŸ”´ |
| **Runbooks** | 1 | 3 | 0 â†’ 3 ğŸ”´ |
| **Ambientes** | 2 (dev, staging) | 3 (+ prod) | 2 â†’ 3 â³ |
| **Cobertura CI95** | â‰¥85% | â‰¥90% | - â†’ 90% ğŸ”´ |
| **MTTR (Mean Time to Restore)** | - | <30min | - â†’ 25min â³ |

---

## ğŸš€ Plano de ExecuÃ§Ã£o

### **Timeline Visual**

```
Semana 4     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â”‚ Testes UnitÃ¡rios
Semana 5     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ Observabilidade
Semana 6     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â”‚ Performance
Semana 7     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ SeguranÃ§a
Semana 8     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ UAT + Cert Bronze
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Semana 9-10  â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ Gates AutomÃ¡ticos
Semana 11-12 â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ CI/CD + Registro
Semana 13-14 â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ Alertas + CanÃ¡rio
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
             ğŸ† PRATA CERTIFICADO
```

---

## ğŸ“ PrÃ³ximos Passos Imediatos

### **ğŸ”´ AÃ‡ÃƒO IMEDIATA (Hoje):**
1. âœ… Criar branch `feat/silver-sprint-2-tests`
2. â³ Setup pytest + pytest-cov
3. â³ Criar fixtures bÃ¡sicos
4. â³ Primeiro teste: `test_prediction_request_validation`

### **ğŸ“… Esta Semana (Semana 4):**
- Completar setup de testes
- Atingir 50% de cobertura em schemas e services
- Documentar estratÃ©gia de testes

### **ğŸ¯ Este MÃªs (Outubro):**
- Completar Sprint 2 e 3
- Certificar Bronze 100%
- Iniciar Sprint 5 (gates)

---

## ğŸ“ LiÃ§Ãµes do Sprint 1 Aplicadas

**âœ… O que funcionou bem:**
- Foco em qualidade cientÃ­fica desde o inÃ­cio
- GovernanÃ§a por headers e logs estruturados
- Fail-soft e graceful degradation

**ğŸ”„ O que melhoraremos:**
- Testes desde o inÃ­cio (nÃ£o deixar para depois)
- Observabilidade early (Prometheus desde Sprint 2)
- Performance testing contÃ­nuo (nÃ£o sÃ³ no final)

---

## ğŸ“š ReferÃªncias

- [ANALISE_MATURIDADE.md](./ANALISE_MATURIDADE.md) - AnÃ¡lise completa de maturidade
- [REQUISITOS.md](./REQUISITOS.md) - Requisitos funcionais e nÃ£o-funcionais
- [GO_LIVE_CHECKLIST.md](./GO_LIVE_CHECKLIST.md) - Checklist de go-live
- [MODEL_CARD_v1.0.2.md](./MODEL_CARD_v1.0.2.md) - ValidaÃ§Ã£o tÃ©cnica do modelo

---

**ğŸŠ Status:** ROADMAP APROVADO  
**ğŸš€ Next:** Sprint 2 - Testes e Observabilidade  
**ğŸ† Goal:** Prata em 6-8 semanas


# ü•à ROADMAP PRATA DETALHADO - QUANTUM-X

**Vers√£o:** 2.0  
**Data:** 2025-10-01  
**Base:** Bronze 100% Certificado ‚úÖ  
**Prazo:** 30-60 dias (15 semanas)  

---

## üìã RESUMO EXECUTIVO

### OBJETIVO PRATA

Evoluir de **Bronze** (modelo bivariado) para **Prata** (small VAR com 4 vari√°veis) mantendo rigor cient√≠fico, auditabilidade e performance, com expans√£o de capacidades anal√≠ticas.

### PRINCIPAIS MUDAN√áAS

**Dados:**
- Bronze: Fed + Selic (2 vari√°veis, 247 obs)
- Prata: **Fed + Selic + Infla√ß√£o + Atividade** (4 vari√°veis, 250+ obs)

**Modelos:**
- Bronze: LP(2) + BVAR(2)
- Prata: **Small BVAR(4)** + LP(4) com Minnesota/Observables priors

**Forecasts:**
- Bronze: Cen√°rios simples
- Prata: **Conditional forecasts** com avalia√ß√£o de efficiency gain

**Inova√ß√£o:**
- Prata: **Gera√ß√£o de cen√°rios via IA** (LLM ‚Üí paths quantitativos)

---

## üìä EXPANS√ÉO DE DADOS (Semanas 6-7)

### Fontes Adicionais

**Brasil (BCB/SGS):**
```python
{
  "ipca_mensal": {
    "serie": 433,
    "frequencia": "mensal",
    "transformacao": "YoY % change"
  },
  "ipca_12m": {
    "serie": 13,
    "frequencia": "mensal",
    "uso": "direto"
  },
  "ibc_br": {
    "serie": 24363,
    "frequencia": "mensal",
    "transformacao": "YoY % change dessazonalizado"
  },
  "pib_trimestral": {
    "serie": 4380,
    "frequencia": "trimestral",
    "interpolacao": "cubic spline ‚Üí mensal"
  }
}
```

**Estados Unidos (FRED):**
```python
{
  "cpi_all_urban": {
    "serie": "CPIAUCSL",
    "frequencia": "mensal",
    "transformacao": "YoY % change"
  },
  "gdp": {
    "serie": "GDP",
    "frequencia": "trimestral",
    "interpolacao": "cubic spline ‚Üí mensal"
  },
  "desemprego": {
    "serie": "UNRATE",
    "frequencia": "mensal",
    "uso": "vari√°vel controle opcional"
  }
}
```

### Pipeline de Ingest√£o

**Arquivo:** `src/data/ingestion/multivariate_pipeline.py`

```python
class MultivariateDataPipeline:
    """
    Pipeline para ingest√£o de dados multivariados
    
    Bronze: 2 vari√°veis (Fed, Selic)
    Prata:  4 vari√°veis (Fed, Selic, Inflation, Activity)
    """
    
    def fetch_brazil_data(self) -> pd.DataFrame:
        """Buscar dados do Brasil (BCB/SGS)"""
        # IPCA 12M
        ipca = fetch_bcb_series(433, start='2005-01-01')
        
        # IBC-Br dessazonalizado YoY
        ibc_br = fetch_bcb_series(24363, start='2005-01-01')
        ibc_br_yoy = ibc_br.pct_change(12) * 100
        
        # PIB trimestral ‚Üí mensal
        pib_tri = fetch_bcb_series(4380, start='2005-01-01')
        pib_mensal = interpolate_quarterly_to_monthly(pib_tri, method='cubic')
        
        return pd.DataFrame({
            'selic': fetch_selic(),
            'ipca_12m': ipca,
            'activity_ibc': ibc_br_yoy,
            'activity_pib': pib_mensal
        })
    
    def fetch_us_data(self) -> pd.DataFrame:
        """Buscar dados dos EUA (FRED)"""
        # CPI YoY
        cpi = fetch_fred_series('CPIAUCSL', start='2005-01-01')
        cpi_yoy = cpi.pct_change(12) * 100
        
        # GDP trimestral ‚Üí mensal
        gdp_tri = fetch_fred_series('GDP', start='2005-01-01')
        gdp_mensal = interpolate_quarterly_to_monthly(gdp_tri, method='cubic')
        
        return pd.DataFrame({
            'fed_rate': fetch_fred_series('FEDFUNDS'),
            'cpi_yoy': cpi_yoy,
            'activity_gdp': gdp_mensal
        })
    
    def merge_and_validate(self, brazil_df, us_df) -> pd.DataFrame:
        """Mesclar dados e validar qualidade"""
        # Merge por index (datas)
        combined = pd.merge(
            brazil_df, us_df, 
            left_index=True, right_index=True, 
            how='inner'
        )
        
        # Valida√ß√µes
        assert len(combined) >= 200, "N muito pequeno ap√≥s merge"
        assert combined.isnull().sum().sum() < len(combined) * 0.05, "Muitos NaNs"
        
        # Selecionar vari√°veis finais
        final = combined[[
            'fed_rate', 'selic', 
            'ipca_12m', 'activity_ibc'  # ou activity_pib
        ]].copy()
        
        final.columns = ['fed_rate', 'selic', 'inflation', 'activity']
        
        return final
```

### Valida√ß√£o de Qualidade Expandida

**Arquivo:** `tests/data_quality/test_multivariate_data.py`

```python
def test_inflation_stationarity():
    """IPCA 12M deve ser I(0) ou I(1) suave"""
    ipca = load_ipca_12m()
    
    # ADF test
    adf_pval = adfuller(ipca.dropna())[1]
    
    # Se n√£o estacion√°rio, diferenciar
    if adf_pval > 0.05:
        d_ipca = ipca.diff().dropna()
        adf_pval_diff = adfuller(d_ipca)[1]
        assert adf_pval_diff < 0.05, "IPCA n√£o estacion√°rio nem em diferen√ßas"

def test_activity_yoy_stationarity():
    """IBC-Br YoY deve ser I(0)"""
    ibc_yoy = load_ibc_br_yoy()
    adf_pval = adfuller(ibc_yoy.dropna())[1]
    assert adf_pval < 0.10, "IBC-Br YoY n√£o estacion√°rio"

def test_data_alignment():
    """Todas as 4 s√©ries devem estar alinhadas temporalmente"""
    data = load_multivariate_data()
    
    # Sem NaNs ap√≥s merge
    assert data.isnull().sum().sum() == 0
    
    # Per√≠odo comum >= 200 obs
    assert len(data) >= 200
```

---

## ü§ñ SMALL BVAR(4) (Semanas 8-9)

### Implementa√ß√£o

**Arquivo:** `src/models/bvar_small.py`

```python
class SmallBVAR(BVARMinnesota):
    """
    Small BVAR(4) com Minnesota Prior
    
    Extens√£o de BVARMinnesota para 4 vari√°veis:
    Y_t = [Fed, Selic, Inflation, Activity]'
    """
    
    def __init__(
        self,
        n_vars: int = 4,          # 4 vari√°veis agora
        n_lags: int = 2,
        lambda1: float = 0.2,     # Shrinkage geral
        lambda2: float = 0.4,     # Cross-equation
        lambda3: float = 1.5,     # Lag decay
        **kwargs
    ):
        super().__init__(
            n_vars=n_vars,
            n_lags=n_lags,
            lambda1=lambda1,
            lambda2=lambda2,
            lambda3=lambda3,
            **kwargs
        )
    
    def structural_irfs_expanded(
        self,
        horizon: int = 12,
        shock_var: int = 0,  # Fed
        response_vars: List[int] = [1, 2, 3]  # Selic, Inflation, Activity
    ) -> Dict[str, np.ndarray]:
        """
        IRFs estruturais com Cholesky
        
        Ordena√ß√£o: Fed ‚Üí Inflation ‚Üí Activity ‚Üí Selic
        """
        # Decomposi√ß√£o de Cholesky
        L = np.linalg.cholesky(self.sigma)
        
        # IRFs estruturais
        irfs = {}
        for resp_var in response_vars:
            irf = self._compute_irf(
                shock_var=shock_var,
                response_var=resp_var,
                horizon=horizon,
                structural=True,
                cholesky_factor=L
            )
            
            var_names = ['fed', 'selic', 'inflation', 'activity']
            irfs[f"{var_names[shock_var]}_to_{var_names[resp_var]}"] = irf
        
        return irfs
    
    def variance_decomposition(
        self,
        horizon: int = 12
    ) -> Dict[str, pd.DataFrame]:
        """
        Decomposi√ß√£o da vari√¢ncia do erro de previs√£o
        
        Retorna contribui√ß√£o de cada choque para vari√¢ncia
        de cada vari√°vel em cada horizonte
        """
        # Implementa√ß√£o via IRFs estruturais
        # ...
        pass
```

### Calibra√ß√£o de Priors

**Arquivo:** `scripts/calibrate_priors_prata.py`

```python
def calibrate_minnesota_priors():
    """
    Calibrar Œª1, Œª2, Œª3 para Small BVAR(4)
    
    M√©todo: Grid search com cross-validation
    """
    data = load_multivariate_data()
    
    # Grid de hiperpar√¢metros
    lambda1_grid = [0.1, 0.15, 0.2, 0.25, 0.3]
    lambda2_grid = [0.3, 0.4, 0.5]
    lambda3_grid = [1.0, 1.5, 2.0]
    
    best_params = None
    best_score = np.inf
    
    for l1, l2, l3 in product(lambda1_grid, lambda2_grid, lambda3_grid):
        # Time-series cross-validation
        scores = []
        for train, test in rolling_origin_cv(data, horizon=6, n_splits=10):
            model = SmallBVAR(
                lambda1=l1, lambda2=l2, lambda3=l3
            )
            model.fit(train)
            
            # Forecast
            fc = model.forecast(horizon=6)
            
            # Score: CRPS m√©dio
            crps = continuous_ranked_probability_score(fc, test['selic'])
            scores.append(crps)
        
        avg_score = np.mean(scores)
        
        if avg_score < best_score:
            best_score = avg_score
            best_params = (l1, l2, l3)
    
    logger.info(f"Best params: Œª1={best_params[0]}, Œª2={best_params[1]}, Œª3={best_params[2]}")
    logger.info(f"Best CRPS: {best_score:.2f}")
    
    return best_params
```

### Testes Cient√≠ficos

**Arquivo:** `tests_scientific/small_bvar/test_small_bvar.py`

```python
def test_stability_small_bvar():
    """Small BVAR(4) deve ser est√°vel"""
    data = load_multivariate_data()
    
    model = SmallBVAR(n_vars=4, n_lags=2)
    model.fit(data)
    
    # Verificar eigenvalues
    assert model.stable, "Modelo inst√°vel!"
    assert np.max(np.abs(model.eigs_F)) < 1.0
    assert np.max(np.abs(model.eigs_F)) < 0.99, "Pr√≥ximo da instabilidade"

def test_irfs_cointegrated():
    """IRFs devem convergir para zero"""
    model = load_trained_small_bvar()
    
    irfs = model.structural_irfs_expanded(horizon=24)
    
    # Verificar converg√™ncia
    for irf_name, irf_values in irfs.items():
        # √öltimos 6 valores devem ser pr√≥ximos de zero
        assert np.abs(irf_values[-6:]).max() < 0.1, \
            f"IRF {irf_name} n√£o converge"

def test_variance_decomposition_sums_to_one():
    """Decomposi√ß√£o deve somar 100% em cada horizonte"""
    model = load_trained_small_bvar()
    
    vd = model.variance_decomposition(horizon=12)
    
    for var_name, vd_df in vd.items():
        # Soma por horizonte deve ser 1.0
        for h in range(12):
            total = vd_df.iloc[h].sum()
            assert np.abs(total - 1.0) < 1e-6, \
                f"{var_name} h={h}: soma={total} != 1.0"
```

---

## üìà FORECASTS CONDICIONAIS (Semanas 10-11)

### M√©todo Waggoner-Zha

**Arquivo:** `src/models/conditional_forecasting.py`

```python
class ConditionalForecaster:
    """
    Forecasts condicionais via Waggoner-Zha
    
    Dado path do Fed, gerar distribui√ß√£o preditiva da Selic
    condicionada ao path.
    """
    
    def __init__(self, bvar_model: SmallBVAR):
        self.bvar = bvar_model
    
    def conditional_forecast(
        self,
        fed_path: List[float],
        horizon: int = 12,
        n_simulations: int = 5000
    ) -> Dict[str, np.ndarray]:
        """
        Forecast condicional dado path do Fed
        
        Args:
            fed_path: Path do Fed para horizontes 1-H
            horizon: Horizonte m√°ximo
            n_simulations: Simula√ß√µes Monte Carlo
        
        Returns:
            Dict com mean, std, quantiles da Selic condicionada
        """
        # Unconditional forecast (baseline)
        uncond = self.bvar.forecast(horizon=horizon, n_simulations=n_simulations)
        
        # Conditional forecast (impor path do Fed)
        cond_sims = []
        
        for sim in range(n_simulations):
            # Simular path completo de Y_t
            y_sim = self._simulate_path(horizon)
            
            # Se path do Fed est√° dentro de toler√¢ncia, aceitar
            if self._check_path_consistency(y_sim[:, 0], fed_path, tol=0.1):
                cond_sims.append(y_sim[:, 1])  # Selic
        
        # Se poucos aceitos, usar m√©todo de otimiza√ß√£o
        if len(cond_sims) < 100:
            cond_sims = self._optimize_conditional_path(fed_path, horizon)
        
        cond_sims = np.array(cond_sims)
        
        return {
            'mean': cond_sims.mean(axis=0),
            'std': cond_sims.std(axis=0),
            'ci95_lower': np.percentile(cond_sims, 2.5, axis=0),
            'ci95_upper': np.percentile(cond_sims, 97.5, axis=0),
            'unconditional_mean': uncond['mean'],
            'efficiency_gain': self._compute_efficiency_gain(cond_sims, uncond)
        }
    
    def _compute_efficiency_gain(
        self,
        cond_sims: np.ndarray,
        uncond_fc: Dict
    ) -> float:
        """
        Efficiency gain = 1 - (Var_cond / Var_uncond)
        
        Quanto maior, melhor o forecast condicional
        """
        var_cond = cond_sims.var(axis=0).mean()
        var_uncond = uncond_fc['std']**2
        
        return 1.0 - (var_cond / var_uncond)
```

### Backtesting Conditional vs Unconditional

**Arquivo:** `tests/backtests/test_conditional_accuracy.py`

```python
def test_conditional_forecast_accuracy():
    """
    Forecasts condicionais devem ter efficiency gain ‚â• 10%
    """
    model = load_trained_small_bvar()
    
    # Backtesting hist√≥rico
    data = load_multivariate_data()
    
    results = []
    
    for t in range(150, len(data) - 12):
        # Train at√© t
        train = data.iloc[:t]
        test = data.iloc[t:t+12]
        
        # Re-estimar
        model.fit(train)
        
        # Unconditional forecast
        uncond = model.forecast(horizon=12)
        
        # Conditional forecast (path real do Fed)
        fed_path = test['fed_rate'].tolist()
        cond = model.conditional_forecast(fed_path=fed_path, horizon=12)
        
        # Avaliar
        rmse_cond = np.sqrt(np.mean((cond['mean'] - test['selic'])**2))
        rmse_uncond = np.sqrt(np.mean((uncond['mean'] - test['selic'])**2))
        
        efficiency = 1.0 - (rmse_cond / rmse_uncond)
        
        results.append({
            'date': test.index[0],
            'rmse_conditional': rmse_cond,
            'rmse_unconditional': rmse_uncond,
            'efficiency_gain': efficiency
        })
    
    # Agrega√ß√£o
    avg_efficiency = np.mean([r['efficiency_gain'] for r in results])
    
    # GATE: efficiency gain ‚â• 10%
    assert avg_efficiency >= 0.10, \
        f"Efficiency gain {avg_efficiency:.2%} < 10%"
    
    logger.info(f"‚úÖ Conditional forecasts: efficiency gain = {avg_efficiency:.2%}")
```

---

## ü§ñ GERA√á√ÉO DE CEN√ÅRIOS VIA IA (Semanas 14-15 - Opcional)

### Integra√ß√£o com LLM

**Arquivo:** `src/ai/scenario_generator.py`

```python
from openai import OpenAI
import anthropic

class AIScenarioGenerator:
    """
    Gerador de cen√°rios econ√¥micos via LLM
    
    Input: Narrativa econ√¥mica (texto livre)
    Output: Path quantitativo do Fed (12 meses)
    """
    
    def __init__(self, provider: str = "openai"):
        self.provider = provider
        self.client = OpenAI() if provider == "openai" else anthropic.Anthropic()
    
    def generate_fed_path_from_narrative(
        self,
        narrative: str,
        current_fed_rate: float = 5.33,
        horizon: int = 12
    ) -> Dict[str, Any]:
        """
        Gerar path do Fed a partir de narrativa econ√¥mica
        
        Args:
            narrative: Texto descrevendo cen√°rio econ√¥mico
            current_fed_rate: Taxa atual do Fed
            horizon: Meses √† frente
        
        Returns:
            Dict com fed_path, confidence, metadata
        """
        prompt = f"""
Voc√™ √© um economista quantitativo. Dado o cen√°rio econ√¥mico abaixo, 
traduza-o em um path plaus√≠vel da taxa de juros do Fed para os 
pr√≥ximos {horizon} meses.

CEN√ÅRIO:
{narrative}

TAXA ATUAL DO FED: {current_fed_rate}%

INSTRU√á√ïES:
1. Retorne path mensal em bps (m√∫ltiplos de 25)
2. Mantenha plausibilidade econ√¥mica (mudan√ßas graduais)
3. Justifique cada movimento
4. Indique n√≠vel de confian√ßa (low/medium/high)

FORMATO DE SA√çDA (JSON):
{{
  "fed_path_bps": [5.33, 5.08, 4.83, ...],  // 12 valores
  "rationale": "Gradual loosening devido a...",
  "confidence": "medium",
  "key_assumptions": ["infla√ß√£o controlada", "crescimento moderado"],
  "severity_check": "plausible"  // severe_but_plausible | implausible
}}
"""
        
        # Chamar LLM
        if self.provider == "openai":
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            result = json.loads(response.choices[0].message.content)
        else:
            # Anthropic Claude
            response = self.client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1024,
                messages=[{"role": "user", "content": prompt}]
            )
            result = json.loads(response.content[0].text)
        
        # Valida√ß√µes
        validated = self._validate_and_sanitize(result, current_fed_rate, horizon)
        
        return validated
    
    def _validate_and_sanitize(
        self,
        llm_output: Dict,
        current_rate: float,
        horizon: int
    ) -> Dict:
        """
        Validar output do LLM e sanitizar
        
        Regras "severe but plausible":
        - Mudan√ßas graduais (max 50 bps/m√™s)
        - Range total razo√°vel (0% - 8%)
        - Sem descontinuidades abruptas
        """
        fed_path = llm_output.get('fed_path_bps', [])
        
        # Valida√ß√£o 1: tamanho correto
        if len(fed_path) != horizon:
            raise ValueError(f"Path com {len(fed_path)} != {horizon} meses")
        
        # Valida√ß√£o 2: m√∫ltiplos de 25
        for rate in fed_path:
            if (rate * 100) % 25 != 0:
                # Arredondar para m√∫ltiplo de 25
                fed_path = [round(r * 4) / 4 for r in fed_path]
                break
        
        # Valida√ß√£o 3: mudan√ßas graduais (max 50 bps/m√™s)
        for i in range(len(fed_path) - 1):
            delta = abs(fed_path[i+1] - fed_path[i]) * 100
            if delta > 50:
                raise ValueError(f"Mudan√ßa abrupta: {delta} bps no m√™s {i+1}")
        
        # Valida√ß√£o 4: range razo√°vel
        if min(fed_path) < 0 or max(fed_path) > 8.0:
            raise ValueError(f"Path fora do range [0%, 8%]: {min(fed_path)}-{max(fed_path)}")
        
        # Adicionar metadata
        llm_output['llm_provider'] = self.provider
        llm_output['llm_model'] = "gpt-4" if self.provider == "openai" else "claude-3-sonnet"
        llm_output['validated'] = True
        llm_output['timestamp'] = datetime.utcnow().isoformat()
        
        return llm_output
```

### Endpoint Expandido

**Adicionar a:** `src/api/endpoints/prediction.py`

```python
@router.post("/selic-from-fed/scenario-ai")
async def predict_from_ai_scenario(
    narrative: str = Body(..., description="Narrativa econ√¥mica"),
    current_fed_rate: float = Body(5.33, description="Taxa atual do Fed"),
    horizon: int = Body(12, ge=1, le=24),
    auth_headers = Depends(get_auth_headers)
):
    """
    Previs√£o de Selic a partir de narrativa econ√¥mica (via IA)
    
    BETA: Usa LLM para traduzir narrativa ‚Üí path do Fed ‚Üí previs√£o Selic
    """
    try:
        # Gerar path via IA
        ai_generator = AIScenarioGenerator(provider="openai")
        
        ai_result = ai_generator.generate_fed_path_from_narrative(
            narrative=narrative,
            current_fed_rate=current_fed_rate,
            horizon=horizon
        )
        
        # Usar path para forecast condicional
        prediction_service = get_prediction_service()
        
        forecast = prediction_service.predict_conditional(
            fed_path=ai_result['fed_path_bps'],
            horizon=horizon
        )
        
        # Adicionar metadata da IA
        forecast['ai_metadata'] = {
            'narrative': narrative,
            'llm_provider': ai_result['llm_provider'],
            'llm_model': ai_result['llm_model'],
            'confidence': ai_result['confidence'],
            'key_assumptions': ai_result['key_assumptions'],
            'severity_check': ai_result['severity_check']
        }
        
        return forecast
    
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao gerar cen√°rio via IA: {str(e)}"
        )
```

---

## üéØ GATE DE PROMO√á√ÉO (Semanas 12-13)

### Configura√ß√£o de Thresholds

**Arquivo:** `configs/gate_thresholds.json`

```json
{
  "version": "1.0",
  "gates": {
    "stability": {
      "max_eigenvalue": 0.99,
      "required": true
    },
    "coverage": {
      "ci95_min": 0.90,
      "ci68_min": 0.65,
      "required": true
    },
    "calibration": {
      "pit_uniformity_pval_min": 0.05,
      "required": true
    },
    "accuracy": {
      "crps_max": 20.0,
      "brier_score_max": 0.25,
      "required": true
    },
    "conditional_efficiency": {
      "efficiency_gain_min": 0.10,
      "required": true,
      "applies_to": ["v2.0.0+"]
    },
    "data_quality": {
      "n_observations_min": 200,
      "max_missing_pct": 0.05,
      "required": true
    }
  },
  "manual_override_allowed": true,
  "override_requires_justification": true
}
```

### Implementa√ß√£o do Gate

**Arquivo:** `src/validation/promotion_gate.py`

```python
class PromotionGate:
    """
    Gate de promo√ß√£o de modelos
    
    Valida se modelo atende thresholds antes de ir para produ√ß√£o
    """
    
    def __init__(self, config_path: str = "configs/gate_thresholds.json"):
        with open(config_path) as f:
            self.config = json.load(f)
        self.gates = self.config['gates']
    
    def evaluate(
        self,
        model_version: str,
        backtest_results: Dict[str, float],
        model_metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Avaliar se modelo passa nos gates
        
        Returns:
            Dict com passed, failed_gates, warnings
        """
        failed_gates = []
        warnings = []
        
        # Gate 1: Stability
        if self.gates['stability']['required']:
            max_eig = model_metadata.get('max_eigenvalue', 1.0)
            if max_eig >= self.gates['stability']['max_eigenvalue']:
                failed_gates.append({
                    'gate': 'stability',
                    'value': max_eig,
                    'threshold': self.gates['stability']['max_eigenvalue'],
                    'message': 'Modelo pr√≥ximo da instabilidade'
                })
        
        # Gate 2: Coverage
        if self.gates['coverage']['required']:
            coverage = backtest_results.get('coverage_ci95', 0.0)
            if coverage < self.gates['coverage']['ci95_min']:
                failed_gates.append({
                    'gate': 'coverage',
                    'value': coverage,
                    'threshold': self.gates['coverage']['ci95_min'],
                    'message': f'Cobertura CI95 {coverage:.2%} < {self.gates["coverage"]["ci95_min"]:.0%}'
                })
        
        # Gate 3: Calibration
        if self.gates['calibration']['required']:
            pit_pval = backtest_results.get('pit_uniformity_pval', 0.0)
            if pit_pval < self.gates['calibration']['pit_uniformity_pval_min']:
                failed_gates.append({
                    'gate': 'calibration',
                    'value': pit_pval,
                    'threshold': self.gates['calibration']['pit_uniformity_pval_min'],
                    'message': 'PIT test falhou (n√£o uniforme)'
                })
        
        # Gate 4: Accuracy
        if self.gates['accuracy']['required']:
            crps = backtest_results.get('crps', 999)
            if crps > self.gates['accuracy']['crps_max']:
                failed_gates.append({
                    'gate': 'accuracy',
                    'value': crps,
                    'threshold': self.gates['accuracy']['crps_max'],
                    'message': f'CRPS {crps:.2f} > {self.gates["accuracy"]["crps_max"]}'
                })
        
        # Gate 5: Conditional Efficiency (Prata)
        gate_cond = self.gates['conditional_efficiency']
        if (gate_cond['required'] and 
            any(model_version >= v for v in gate_cond['applies_to'])):
            
            eff_gain = backtest_results.get('conditional_efficiency_gain', 0.0)
            if eff_gain < gate_cond['efficiency_gain_min']:
                failed_gates.append({
                    'gate': 'conditional_efficiency',
                    'value': eff_gain,
                    'threshold': gate_cond['efficiency_gain_min'],
                    'message': f'Efficiency gain {eff_gain:.2%} < 10%'
                })
        
        # Resultado
        passed = len(failed_gates) == 0
        
        return {
            'passed': passed,
            'failed_gates': failed_gates,
            'warnings': warnings,
            'manual_override_allowed': self.config['manual_override_allowed'],
            'evaluated_at': datetime.utcnow().isoformat()
        }
```

### Teste do Gate

**Arquivo:** `tests/unit/test_promotion_gate.py`

```python
def test_gate_rejects_unstable_model():
    """Gate deve rejeitar modelo inst√°vel"""
    gate = PromotionGate()
    
    # Modelo com max eigenvalue = 1.05 (INST√ÅVEL)
    result = gate.evaluate(
        model_version="v2.0.0",
        backtest_results={'coverage_ci95': 0.95, 'crps': 15.0},
        model_metadata={'max_eigenvalue': 1.05}
    )
    
    assert not result['passed']
    assert any(g['gate'] == 'stability' for g in result['failed_gates'])

def test_gate_rejects_low_coverage():
    """Gate deve rejeitar modelo com cobertura baixa"""
    gate = PromotionGate()
    
    result = gate.evaluate(
        model_version="v2.0.0",
        backtest_results={'coverage_ci95': 0.85, 'crps': 15.0},  # < 90%
        model_metadata={'max_eigenvalue': 0.4}
    )
    
    assert not result['passed']
    assert any(g['gate'] == 'coverage' for g in result['failed_gates'])

def test_gate_accepts_good_model():
    """Gate deve aceitar modelo que atende todos os thresholds"""
    gate = PromotionGate()
    
    result = gate.evaluate(
        model_version="v2.0.0",
        backtest_results={
            'coverage_ci95': 0.94,
            'pit_uniformity_pval': 0.42,
            'crps': 12.1,
            'brier_score': 0.14,
            'conditional_efficiency_gain': 0.18
        },
        model_metadata={
            'max_eigenvalue': 0.41,
            'n_observations': 250
        }
    )
    
    assert result['passed']
    assert len(result['failed_gates']) == 0
```

---

## üìä M√âTRICAS EXPANDIDAS (API Response)

### Response com M√©tricas de Qualidade

```json
{
  "expected_move_bps": 18,
  "horizon_months": "1-3",
  "distribution": [...],
  "per_meeting": [...],
  "model_metadata": {
    "version": "v2.0.0",
    "variables": ["fed_rate", "selic", "inflation", "activity"],
    "methodology": "Small BVAR(4) with Minnesota prior",
    "backtest_metrics": {
      "coverage_ci95": 0.94,
      "crps": 12.1,
      "conditional_efficiency_gain": 0.18
    }
  },
  "forecast_quality": {
    "conditional": true,
    "efficiency_gain_vs_unconditional": 0.18,
    "coverage_rate_ci95": 0.94,
    "calibration_score": 0.89
  },
  "variance_decomposition": {
    "fed_contribution_pct": 45,
    "inflation_contribution_pct": 35,
    "activity_contribution_pct": 20
  },
  "rationale_expanded": "Small BVAR(4) indica resposta positiva da Selic (+18 bps esperado em 3 meses) ao choque de +25 bps do Fed. Infla√ß√£o contribui 35% da vari√¢ncia do erro de previs√£o, atividade 20%, Fed 45%. Forecast condicional 18% mais preciso que incondicional."
}
```

---

## üéØ DELIVERABLES PRATA (Checklist)

### Dados (Semanas 6-7)

- [ ] Pipeline de ingest√£o BCB/FRED expandido
- [ ] 4 s√©ries temporais integradas (Fed, Selic, Inflation, Activity)
- [ ] Interpola√ß√£o trimestral‚Üímensal validada
- [ ] N ‚â• 200 observa√ß√µes alinhadas
- [ ] Testes de estacionariedade aprovados
- [ ] Data hash SHA-256 atualizado

### Modelos (Semanas 8-9)

- [ ] SmallBVAR(4) implementado
- [ ] Priors calibrados por cross-validation
- [ ] Estabilidade verificada (eigenvalues < 1.0)
- [ ] IRFs estruturais expandidos (Fed‚ÜíSelic, Fed‚ÜíInflation, Fed‚ÜíActivity)
- [ ] Variance decomposition implementada
- [ ] Testes cient√≠ficos do small VAR passando

### Forecasts Condicionais (Semanas 10-11)

- [ ] M√©todo Waggoner-Zha implementado
- [ ] 20+ cen√°rios can√¥nicos gerados
- [ ] Backtesting conditional vs unconditional
- [ ] Efficiency gain ‚â• 10% validado
- [ ] Coverage CI95 ‚â• 92%
- [ ] PIT uniformity p-value ‚â• 0.05

### Gate e Promo√ß√£o (Semanas 12-13)

- [ ] `gate_thresholds.json` criado
- [ ] `PromotionGate` implementado
- [ ] Testes de gate passando (aceita/rejeita corretamente)
- [ ] Canary deployment de v2.0.0
- [ ] Monitoramento de m√©tricas de produ√ß√£o
- [ ] Promo√ß√£o ou rollback decidido

### IA (Semanas 14-15 - Opcional)

- [ ] `AIScenarioGenerator` implementado
- [ ] Integra√ß√£o OpenAI/Anthropic
- [ ] Validador "severe but plausible"
- [ ] Endpoint `/scenario-ai` funcional
- [ ] Testes de coer√™ncia econ√¥mica
- [ ] Logs de metadata (prompt, LLM usado)

### Documenta√ß√£o

- [ ] Model Card v2.0.0 completo
- [ ] README atualizado com Prata
- [ ] API_README com novos endpoints
- [ ] Relat√≥rio de backtesting expandido
- [ ] Guia de gera√ß√£o de cen√°rios via IA

---

## üèÜ CRIT√âRIOS DE ACEITA√á√ÉO PRATA

### Funcional

- [ ] Small BVAR(4) em produ√ß√£o
- [ ] Forecasts condicionais com efficiency gain ‚â• 10%
- [ ] Variance decomposition dispon√≠vel na API
- [ ] Cen√°rios via IA funcionais (beta)
- [ ] Fallback robusto se IA falhar

### N√£o-Funcional

- [ ] P95 lat√™ncia < 300 ms (small VAR mais pesado)
- [ ] Coverage CI95 ‚â• 92%
- [ ] CRPS ‚â§ 18.0
- [ ] PIT uniformity p-value ‚â• 0.05
- [ ] Disponibilidade ‚â• 99.95% mensal
- [ ] Tempo de re-treino < 30 minutos

### Qualidade

- [ ] Testes expandidos (conditional, gate, AI)
- [ ] Coverage ‚â• 75% (com novos m√≥dulos)
- [ ] Types estritos mantidos
- [ ] Error handling robusto em IA

### Documenta√ß√£o

- [ ] Model Cards v2.0
- [ ] Relat√≥rios de backtesting completos
- [ ] Guias de uso de cen√°rios via IA
- [ ] Runbook atualizado

---

## üìÖ TIMELINE DETALHADO

```
Semanas 1-5:  ‚úÖ BRONZE COMPLETO
Semanas 6-7:  üìä Expans√£o de Dados
Semanas 8-9:  ü§ñ Small BVAR(4)
Semanas 10-11: üìà Forecasts Condicionais
Semanas 12-13: üéØ Gate e Promo√ß√£o
Semanas 14-15: ü§ñ IA (Opcional)

TOTAL: 10-15 semanas (30-60 dias)
```

---

**ü•à PRATA: SISTEMA ANAL√çTICO ROBUSTO COM IA! ü•à**

**Ready to scale to full internal use!** üöÄ

